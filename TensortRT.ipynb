{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7RygVme0yf",
        "outputId": "90496ae1-a70b-4106-a96a-309717b01342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azl6uS7owlNZ",
        "outputId": "a23730d3-3de1-40cd-aec7-7d1907a184fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5.\n",
            "(Reading database ... 124027 files and directories currently installed.)\n",
            "Preparing to unpack .../nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5_1.0-1_amd64.deb ...\n",
            "Unpacking nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5 (1.0-1) ...\n",
            "Setting up nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5 (1.0-1) ...\n",
            "\n",
            "The public nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5 GPG key does not appear to be installed.\n",
            "To install the key, run this command:\n",
            "sudo cp /var/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5/nv-tensorrt-local-012FC2A5-keyring.gpg /usr/share/keyrings/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!sudo dpkg -i \"/content/drive/My Drive/thesis/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5_1.0-1_amd64.deb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQRtCK44wspL",
        "outputId": "29c1ae1f-22a0-4769-a5e7-bec44c4ce0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/var/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5/nv-tensorrt-local-012FC2A5-keyring.gpg': No such file or directory\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "gpg: can't open '/var/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5/nv-tensorrt-local-012FC2A5-keyring.gpg': No such file or directory\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,172 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,616 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,501 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,223 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,734 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,452 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,323 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,512 kB]\n",
            "Fetched 23.9 MB in 3s (8,882 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!sudo cp /var/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5/nv-tensorrt-local-012FC2A5-keyring.gpg /usr/share/keyrings/\n",
        "!sudo apt-key add /var/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5/nv-tensorrt-local-012FC2A5-keyring.gpg\n",
        "!sudo apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqJMquRWwyxy",
        "outputId": "c82dfea4-02aa-4207-951e-45e6f606b031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-bin libnvinfer-dev libnvinfer-dispatch-dev libnvinfer-dispatch10\n",
            "  libnvinfer-headers-dev libnvinfer-headers-plugin-dev libnvinfer-lean-dev\n",
            "  libnvinfer-lean10 libnvinfer-plugin-dev libnvinfer-plugin10\n",
            "  libnvinfer-samples libnvinfer-vc-plugin-dev libnvinfer-vc-plugin10\n",
            "  libnvinfer10 libnvonnxparsers-dev libnvonnxparsers10 python3-libnvinfer\n",
            "  python3-libnvinfer-dev python3-libnvinfer-dispatch python3-libnvinfer-lean\n",
            "  tensorrt tensorrt-dev tensorrt-libs\n",
            "0 upgraded, 23 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,682 MB of archives.\n",
            "After this operation, 6,845 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer10 10.2.0.19-1+cuda12.5 [1,216 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-lean10 10.2.0.19-1+cuda12.5 [9,412 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin10 10.2.0.19-1+cuda12.5 [10.0 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-vc-plugin10 10.2.0.19-1+cuda12.5 [243 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dispatch10 10.2.0.19-1+cuda12.5 [206 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers10 10.2.0.19-1+cuda12.5 [918 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-bin 10.2.0.19-1+cuda12.5 [453 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-dev 10.2.0.19-1+cuda12.5 [108 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dev 10.2.0.19-1+cuda12.5 [1,221 MB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dispatch-dev 10.2.0.19-1+cuda12.5 [113 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-plugin-dev 10.2.0.19-1+cuda12.5 [6,056 B]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-lean-dev 10.2.0.19-1+cuda12.5 [22.1 MB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin-dev 10.2.0.19-1+cuda12.5 [10.2 MB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-vc-plugin-dev 10.2.0.19-1+cuda12.5 [107 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers-dev 10.2.0.19-1+cuda12.5 [1,857 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-samples 10.2.0.19-1+cuda12.5 [187 MB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer 10.2.0.19-1+cuda12.5 [746 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer-lean 10.2.0.19-1+cuda12.5 [452 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer-dispatch 10.2.0.19-1+cuda12.5 [452 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer-dev 10.2.0.19-1+cuda12.5 [2,962 B]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  tensorrt 10.2.0.19-1+cuda12.5 [2,946 B]\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  tensorrt-dev 10.2.0.19-1+cuda12.5 [2,926 B]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  tensorrt-libs 10.2.0.19-1+cuda12.5 [2,926 B]\n",
            "Fetched 2,682 MB in 33s (81.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 23.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libnvinfer10.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libnvinfer10_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer10 (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-lean10.\n",
            "Preparing to unpack .../01-libnvinfer-lean10_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-lean10 (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-plugin10.\n",
            "Preparing to unpack .../02-libnvinfer-plugin10_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin10 (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-vc-plugin10.\n",
            "Preparing to unpack .../03-libnvinfer-vc-plugin10_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-vc-plugin10 (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-dispatch10.\n",
            "Preparing to unpack .../04-libnvinfer-dispatch10_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-dispatch10 (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvonnxparsers10.\n",
            "Preparing to unpack .../05-libnvonnxparsers10_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvonnxparsers10 (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-bin.\n",
            "Preparing to unpack .../06-libnvinfer-bin_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-bin (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-headers-dev.\n",
            "Preparing to unpack .../07-libnvinfer-headers-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "Preparing to unpack .../08-libnvinfer-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-dispatch-dev.\n",
            "Preparing to unpack .../09-libnvinfer-dispatch-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-dispatch-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-headers-plugin-dev.\n",
            "Preparing to unpack .../10-libnvinfer-headers-plugin-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-plugin-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-lean-dev.\n",
            "Preparing to unpack .../11-libnvinfer-lean-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-lean-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-plugin-dev.\n",
            "Preparing to unpack .../12-libnvinfer-plugin-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-vc-plugin-dev.\n",
            "Preparing to unpack .../13-libnvinfer-vc-plugin-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvinfer-vc-plugin-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvonnxparsers-dev.\n",
            "Preparing to unpack .../14-libnvonnxparsers-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking libnvonnxparsers-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package libnvinfer-samples.\n",
            "Preparing to unpack .../15-libnvinfer-samples_10.2.0.19-1+cuda12.5_all.deb ...\n",
            "Unpacking libnvinfer-samples (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package python3-libnvinfer.\n",
            "Preparing to unpack .../16-python3-libnvinfer_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking python3-libnvinfer (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package python3-libnvinfer-lean.\n",
            "Preparing to unpack .../17-python3-libnvinfer-lean_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-lean (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package python3-libnvinfer-dispatch.\n",
            "Preparing to unpack .../18-python3-libnvinfer-dispatch_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-dispatch (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package python3-libnvinfer-dev.\n",
            "Preparing to unpack .../19-python3-libnvinfer-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package tensorrt.\n",
            "Preparing to unpack .../20-tensorrt_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking tensorrt (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package tensorrt-dev.\n",
            "Preparing to unpack .../21-tensorrt-dev_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking tensorrt-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Selecting previously unselected package tensorrt-libs.\n",
            "Preparing to unpack .../22-tensorrt-libs_10.2.0.19-1+cuda12.5_amd64.deb ...\n",
            "Unpacking tensorrt-libs (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-headers-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer10 (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-plugin10 (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-vc-plugin10 (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvonnxparsers10 (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-dispatch10 (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-dispatch-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-lean10 (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvonnxparsers-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up python3-libnvinfer-dispatch (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-headers-plugin-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-lean-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up tensorrt-libs (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up python3-libnvinfer (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up python3-libnvinfer-lean (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-plugin-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-vc-plugin-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-bin (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up libnvinfer-samples (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up tensorrt-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up python3-libnvinfer-dev (10.2.0.19-1+cuda12.5) ...\n",
            "Setting up tensorrt (10.2.0.19-1+cuda12.5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "libnvinfer-bin set on hold.\n",
            "libnvinfer-dev set on hold.\n",
            "libnvinfer-dispatch-dev set on hold.\n",
            "libnvinfer-dispatch10 set on hold.\n",
            "libnvinfer-headers-dev set on hold.\n",
            "libnvinfer-headers-plugin-dev set on hold.\n",
            "libnvinfer-lean-dev set on hold.\n",
            "libnvinfer-lean10 set on hold.\n",
            "libnvinfer-plugin-dev set on hold.\n",
            "libnvinfer-plugin10 set on hold.\n",
            "libnvinfer-samples set on hold.\n",
            "libnvinfer-vc-plugin-dev set on hold.\n",
            "libnvinfer-vc-plugin10 set on hold.\n",
            "libnvinfer10 set on hold.\n",
            "libnvonnxparsers-dev set on hold.\n",
            "libnvonnxparsers10 set on hold.\n",
            "python3-libnvinfer-dev set on hold.\n",
            "python3-libnvinfer-dispatch set on hold.\n",
            "python3-libnvinfer-lean set on hold.\n",
            "python3-libnvinfer set on hold.\n",
            "tensorrt-dev set on hold.\n",
            "tensorrt-libs set on hold.\n",
            "tensorrt set on hold.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install libnvinfer-bin=10.2.0.19-1+cuda12.5 libnvinfer-dev=10.2.0.19-1+cuda12.5 libnvinfer-dispatch-dev=10.2.0.19-1+cuda12.5 libnvinfer-dispatch10=10.2.0.19-1+cuda12.5 libnvinfer-headers-dev=10.2.0.19-1+cuda12.5 libnvinfer-headers-plugin-dev=10.2.0.19-1+cuda12.5 libnvinfer-lean-dev=10.2.0.19-1+cuda12.5 libnvinfer-lean10=10.2.0.19-1+cuda12.5 libnvinfer-plugin-dev=10.2.0.19-1+cuda12.5 libnvinfer-plugin10=10.2.0.19-1+cuda12.5 libnvinfer-samples=10.2.0.19-1+cuda12.5 libnvinfer-vc-plugin-dev=10.2.0.19-1+cuda12.5 libnvinfer-vc-plugin10=10.2.0.19-1+cuda12.5 libnvinfer10=10.2.0.19-1+cuda12.5 libnvonnxparsers-dev=10.2.0.19-1+cuda12.5 libnvonnxparsers10=10.2.0.19-1+cuda12.5 python3-libnvinfer-dev=10.2.0.19-1+cuda12.5 python3-libnvinfer-dispatch=10.2.0.19-1+cuda12.5 python3-libnvinfer-lean=10.2.0.19-1+cuda12.5 python3-libnvinfer=10.2.0.19-1+cuda12.5 tensorrt-dev=10.2.0.19-1+cuda12.5 tensorrt-libs=10.2.0.19-1+cuda12.5 tensorrt=10.2.0.19-1+cuda12.5\n",
        "!sudo apt-mark hold libnvinfer-bin libnvinfer-dev libnvinfer-dispatch-dev libnvinfer-dispatch10 libnvinfer-headers-dev libnvinfer-headers-plugin-dev libnvinfer-lean-dev libnvinfer-lean10 libnvinfer-plugin-dev libnvinfer-plugin10 libnvinfer-samples libnvinfer-vc-plugin-dev libnvinfer-vc-plugin10 libnvinfer10 libnvonnxparsers-dev libnvonnxparsers10 python3-libnvinfer-dev python3-libnvinfer-dispatch python3-libnvinfer-lean python3-libnvinfer tensorrt-dev tensorrt-libs tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -l | grep TensorRT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLUR6QZ1-Q6M",
        "outputId": "9b1e5a0a-db6c-4c59-c801-e8e82eee7183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi  libnvinfer-bin                         10.2.0.19-1+cuda12.5                    amd64        TensorRT binaries\n",
            "hi  libnvinfer-dev                         10.2.0.19-1+cuda12.5                    amd64        TensorRT development libraries\n",
            "hi  libnvinfer-dispatch-dev                10.2.0.19-1+cuda12.5                    amd64        TensorRT development dispatch runtime libraries\n",
            "hi  libnvinfer-dispatch10                  10.2.0.19-1+cuda12.5                    amd64        TensorRT dispatch runtime library\n",
            "hi  libnvinfer-headers-dev                 10.2.0.19-1+cuda12.5                    amd64        TensorRT development headers\n",
            "hi  libnvinfer-headers-plugin-dev          10.2.0.19-1+cuda12.5                    amd64        TensorRT plugin headers\n",
            "hi  libnvinfer-lean-dev                    10.2.0.19-1+cuda12.5                    amd64        TensorRT lean runtime libraries\n",
            "hi  libnvinfer-lean10                      10.2.0.19-1+cuda12.5                    amd64        TensorRT lean runtime library\n",
            "hi  libnvinfer-plugin-dev                  10.2.0.19-1+cuda12.5                    amd64        TensorRT plugin libraries\n",
            "hi  libnvinfer-plugin10                    10.2.0.19-1+cuda12.5                    amd64        TensorRT plugin libraries\n",
            "hi  libnvinfer-samples                     10.2.0.19-1+cuda12.5                    all          TensorRT samples\n",
            "hi  libnvinfer-vc-plugin-dev               10.2.0.19-1+cuda12.5                    amd64        TensorRT vc-plugin library\n",
            "hi  libnvinfer-vc-plugin10                 10.2.0.19-1+cuda12.5                    amd64        TensorRT vc-plugin library\n",
            "hi  libnvinfer10                           10.2.0.19-1+cuda12.5                    amd64        TensorRT runtime libraries\n",
            "hi  libnvonnxparsers-dev                   10.2.0.19-1+cuda12.5                    amd64        TensorRT ONNX libraries\n",
            "hi  libnvonnxparsers10                     10.2.0.19-1+cuda12.5                    amd64        TensorRT ONNX libraries\n",
            "hi  python3-libnvinfer                     10.2.0.19-1+cuda12.5                    amd64        Python 3 bindings for TensorRT standard runtime\n",
            "hi  python3-libnvinfer-dev                 10.2.0.19-1+cuda12.5                    amd64        Python 3 development package for TensorRT standard runtime\n",
            "hi  python3-libnvinfer-dispatch            10.2.0.19-1+cuda12.5                    amd64        Python 3 bindings for TensorRT dispatch runtime\n",
            "hi  python3-libnvinfer-lean                10.2.0.19-1+cuda12.5                    amd64        Python 3 bindings for TensorRT lean runtime\n",
            "hi  tensorrt                               10.2.0.19-1+cuda12.5                    amd64        Meta package for TensorRT\n",
            "hi  tensorrt-dev                           10.2.0.19-1+cuda12.5                    amd64        Meta package for TensorRT development libraries\n",
            "hi  tensorrt-libs                          10.2.0.19-1+cuda12.5                    amd64        Meta package for TensorRT runtime libraries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo find / -name \"*tensorrt*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MrH2wHsTTzH",
        "outputId": "f8eff95f-1917-4c46-8d4f-63f5a7c7b7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/var/lib/dpkg/info/tensorrt-dev.md5sums\n",
            "/var/lib/dpkg/info/tensorrt.md5sums\n",
            "/var/lib/dpkg/info/tensorrt.list\n",
            "/var/lib/dpkg/info/tensorrt-libs.list\n",
            "/var/lib/dpkg/info/tensorrt-libs.md5sums\n",
            "/var/lib/dpkg/info/tensorrt-dev.list\n",
            "/usr/src/tensorrt\n",
            "/usr/src/tensorrt/samples/python/yolov3_onnx/onnx_to_tensorrt.py\n",
            "/usr/share/doc/tensorrt-10.2.0.19\n",
            "/usr/share/doc/tensorrt-dev\n",
            "/usr/share/doc/tensorrt\n",
            "/usr/share/doc/tensorrt-libs\n",
            "/usr/lib/python3.10/dist-packages/tensorrt_lean-10.2.0.dist-info\n",
            "/usr/lib/python3.10/dist-packages/tensorrt\n",
            "/usr/lib/python3.10/dist-packages/tensorrt/tensorrt.so\n",
            "/usr/lib/python3.10/dist-packages/tensorrt_dispatch\n",
            "/usr/lib/python3.10/dist-packages/tensorrt_dispatch/tensorrt_dispatch.so\n",
            "/usr/lib/python3.10/dist-packages/tensorrt_lean\n",
            "/usr/lib/python3.10/dist-packages/tensorrt_lean/tensorrt_lean.so\n",
            "/usr/lib/python3.10/dist-packages/tensorrt_dispatch-10.2.0.dist-info\n",
            "/usr/lib/python3.10/dist-packages/tensorrt-10.2.0.dist-info\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/compiler/tensorrt\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/compiler/tf2tensorrt\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/experimental/tensorrt\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v2/experimental/tensorrt\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/include/tensorflow/compiler/tf2tensorrt\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/tensorrt.py\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/backend_config/tensorrt.py\n",
            "find: ‘/proc/64/task/64/net’: Invalid argument\n",
            "find: ‘/proc/64/net’: Invalid argument\n",
            "find: ‘/proc/844/task/844/net’: Invalid argument\n",
            "find: ‘/proc/844/net’: Invalid argument\n",
            "/content/drive/MyDrive/thesis/nv-tensorrt-local-repo-ubuntu2204-10.2.0-cuda-12.5_1.0-1_amd64.deb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gl6Zb6Aw1x5"
      },
      "outputs": [],
      "source": [
        "# we need to copy tensorrt.so tensorrt_lean.so and tensorrt_dispatch.so from\n",
        "# /usr/lib/python3.10/dist-packages/ to /usr/local/lib/python3.10/dist-packages/\n",
        "!sudo cp -r /usr/lib/python3.10/dist-packages/tensorrt /usr/local/lib/python3.10/dist-packages/\n",
        "!sudo cp -r /usr/lib/python3.10/dist-packages/tensorrt_lean /usr/local/lib/python3.10/dist-packages/\n",
        "!sudo cp -r /usr/lib/python3.10/dist-packages/tensorrt_dispatch /usr/local/lib/python3.10/dist-packages/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWq7Wwy0w2RJ",
        "outputId": "80ceff61-3f8c-4131-9c08-8f4bf21d4dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2024.1.16-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660545 sha256=9b0ecb91630edec67485fdf9a436cafb41b8ecb26353be80859a64e541a494da\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.6 pycuda-2024.1.2 pytools-2024.1.16\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host=files.pythonhosted.org\n",
        "!pip install pycuda\n",
        "!pip install onnxruntime onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cTkMANrxNC_V",
        "outputId": "c676add2-2de2-43f2-ff8e-d77803663338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&&&& RUNNING TensorRT.trtexec [TensorRT v100200] # /usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/dfan.onnx --saveEngine=./models/dfan.trt\n",
            "[11/25/2024-09:02:11] [I] === Model Options ===\n",
            "[11/25/2024-09:02:11] [I] Format: ONNX\n",
            "[11/25/2024-09:02:11] [I] Model: ./models/dfan.onnx\n",
            "[11/25/2024-09:02:11] [I] Output:\n",
            "[11/25/2024-09:02:11] [I] === Build Options ===\n",
            "[11/25/2024-09:02:11] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
            "[11/25/2024-09:02:11] [I] avgTiming: 8\n",
            "[11/25/2024-09:02:11] [I] Precision: FP32+INT8\n",
            "[11/25/2024-09:02:11] [I] LayerPrecisions: \n",
            "[11/25/2024-09:02:11] [I] Layer Device Types: \n",
            "[11/25/2024-09:02:11] [I] Calibration: Dynamic\n",
            "[11/25/2024-09:02:11] [I] Refit: Disabled\n",
            "[11/25/2024-09:02:11] [I] Strip weights: Disabled\n",
            "[11/25/2024-09:02:11] [I] Version Compatible: Disabled\n",
            "[11/25/2024-09:02:11] [I] ONNX Plugin InstanceNorm: Disabled\n",
            "[11/25/2024-09:02:11] [I] TensorRT runtime: full\n",
            "[11/25/2024-09:02:11] [I] Lean DLL Path: \n",
            "[11/25/2024-09:02:11] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
            "[11/25/2024-09:02:11] [I] Exclude Lean Runtime: Disabled\n",
            "[11/25/2024-09:02:11] [I] Sparsity: Disabled\n",
            "[11/25/2024-09:02:11] [I] Safe mode: Disabled\n",
            "[11/25/2024-09:02:11] [I] Build DLA standalone loadable: Disabled\n",
            "[11/25/2024-09:02:11] [I] Allow GPU fallback for DLA: Disabled\n",
            "[11/25/2024-09:02:11] [I] DirectIO mode: Disabled\n",
            "[11/25/2024-09:02:11] [I] Restricted mode: Disabled\n",
            "[11/25/2024-09:02:11] [I] Skip inference: Disabled\n",
            "[11/25/2024-09:02:11] [I] Save engine: ./models/dfan.trt\n",
            "[11/25/2024-09:02:11] [I] Load engine: \n",
            "[11/25/2024-09:02:11] [I] Profiling verbosity: 0\n",
            "[11/25/2024-09:02:11] [I] Tactic sources: Using default tactic sources\n",
            "[11/25/2024-09:02:11] [I] timingCacheMode: local\n",
            "[11/25/2024-09:02:11] [I] timingCacheFile: \n",
            "[11/25/2024-09:02:11] [I] Enable Compilation Cache: Enabled\n",
            "[11/25/2024-09:02:11] [I] errorOnTimingCacheMiss: Disabled\n",
            "[11/25/2024-09:02:11] [I] Preview Features: Use default preview flags.\n",
            "[11/25/2024-09:02:11] [I] MaxAuxStreams: -1\n",
            "[11/25/2024-09:02:11] [I] BuilderOptimizationLevel: -1\n",
            "[11/25/2024-09:02:11] [I] Calibration Profile Index: 0\n",
            "[11/25/2024-09:02:11] [I] Weight Streaming: Disabled\n",
            "[11/25/2024-09:02:11] [I] Runtime Platform: Same As Build\n",
            "[11/25/2024-09:02:11] [I] Debug Tensors: \n",
            "[11/25/2024-09:02:11] [I] Input(s)s format: fp32:CHW\n",
            "[11/25/2024-09:02:11] [I] Output(s)s format: fp32:CHW\n",
            "[11/25/2024-09:02:11] [I] Input build shapes: model\n",
            "[11/25/2024-09:02:11] [I] Input calibration shapes: model\n",
            "[11/25/2024-09:02:11] [I] === System Options ===\n",
            "[11/25/2024-09:02:11] [I] Device: 0\n",
            "[11/25/2024-09:02:11] [I] DLACore: \n",
            "[11/25/2024-09:02:11] [I] Plugins:\n",
            "[11/25/2024-09:02:11] [I] setPluginsToSerialize:\n",
            "[11/25/2024-09:02:11] [I] dynamicPlugins:\n",
            "[11/25/2024-09:02:11] [I] ignoreParsedPluginLibs: 0\n",
            "[11/25/2024-09:02:11] [I] \n",
            "[11/25/2024-09:02:11] [I] === Inference Options ===\n",
            "[11/25/2024-09:02:11] [I] Batch: Explicit\n",
            "[11/25/2024-09:02:11] [I] Input inference shapes: model\n",
            "[11/25/2024-09:02:11] [I] Iterations: 10\n",
            "[11/25/2024-09:02:11] [I] Duration: 3s (+ 200ms warm up)\n",
            "[11/25/2024-09:02:11] [I] Sleep time: 0ms\n",
            "[11/25/2024-09:02:11] [I] Idle time: 0ms\n",
            "[11/25/2024-09:02:11] [I] Inference Streams: 1\n",
            "[11/25/2024-09:02:11] [I] ExposeDMA: Disabled\n",
            "[11/25/2024-09:02:11] [I] Data transfers: Enabled\n",
            "[11/25/2024-09:02:11] [I] Spin-wait: Disabled\n",
            "[11/25/2024-09:02:11] [I] Multithreading: Disabled\n",
            "[11/25/2024-09:02:11] [I] CUDA Graph: Disabled\n",
            "[11/25/2024-09:02:11] [I] Separate profiling: Disabled\n",
            "[11/25/2024-09:02:11] [I] Time Deserialize: Disabled\n",
            "[11/25/2024-09:02:11] [I] Time Refit: Disabled\n",
            "[11/25/2024-09:02:11] [I] NVTX verbosity: 0\n",
            "[11/25/2024-09:02:11] [I] Persistent Cache Ratio: 0\n",
            "[11/25/2024-09:02:11] [I] Optimization Profile Index: 0\n",
            "[11/25/2024-09:02:11] [I] Weight Streaming Budget: 100.000000%\n",
            "[11/25/2024-09:02:11] [I] Inputs:\n",
            "[11/25/2024-09:02:11] [I] Debug Tensor Save Destinations:\n",
            "[11/25/2024-09:02:11] [I] === Reporting Options ===\n",
            "[11/25/2024-09:02:11] [I] Verbose: Disabled\n",
            "[11/25/2024-09:02:11] [I] Averages: 10 inferences\n",
            "[11/25/2024-09:02:11] [I] Percentiles: 90,95,99\n",
            "[11/25/2024-09:02:11] [I] Dump refittable layers:Disabled\n",
            "[11/25/2024-09:02:11] [I] Dump output: Disabled\n",
            "[11/25/2024-09:02:11] [I] Profile: Disabled\n",
            "[11/25/2024-09:02:11] [I] Export timing to JSON file: \n",
            "[11/25/2024-09:02:11] [I] Export output to JSON file: \n",
            "[11/25/2024-09:02:11] [I] Export profile to JSON file: \n",
            "[11/25/2024-09:02:11] [I] \n",
            "[11/25/2024-09:02:11] [I] === Device Information ===\n",
            "[11/25/2024-09:02:11] [I] Available Devices: \n",
            "[11/25/2024-09:02:11] [I]   Device 0: \"Tesla T4\" UUID: GPU-6f5efd2e-d728-47a1-a49f-d4d42c1a85af\n",
            "[11/25/2024-09:02:11] [I] Selected Device: Tesla T4\n",
            "[11/25/2024-09:02:11] [I] Selected Device ID: 0\n",
            "[11/25/2024-09:02:11] [I] Selected Device UUID: GPU-6f5efd2e-d728-47a1-a49f-d4d42c1a85af\n",
            "[11/25/2024-09:02:11] [I] Compute Capability: 7.5\n",
            "[11/25/2024-09:02:11] [I] SMs: 40\n",
            "[11/25/2024-09:02:11] [I] Device Global Memory: 15102 MiB\n",
            "[11/25/2024-09:02:11] [I] Shared Memory per SM: 64 KiB\n",
            "[11/25/2024-09:02:11] [I] Memory Bus Width: 256 bits (ECC enabled)\n",
            "[11/25/2024-09:02:11] [I] Application Compute Clock Rate: 1.59 GHz\n",
            "[11/25/2024-09:02:11] [I] Application Memory Clock Rate: 5.001 GHz\n",
            "[11/25/2024-09:02:11] [I] \n",
            "[11/25/2024-09:02:11] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
            "[11/25/2024-09:02:11] [I] \n",
            "[11/25/2024-09:02:11] [I] TensorRT version: 10.2.0\n",
            "[11/25/2024-09:02:11] [I] Loading standard plugins\n",
            "[11/25/2024-09:02:12] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 16, GPU 103 (MiB)\n",
            "[11/25/2024-09:02:19] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +904, GPU +180, now: CPU 1073, GPU 283 (MiB)\n",
            "[11/25/2024-09:02:19] [I] Start parsing network model.\n",
            "[11/25/2024-09:02:19] [I] [TRT] ----------------------------------------------------------------\n",
            "[11/25/2024-09:02:19] [I] [TRT] Input filename:   ./models/dfan.onnx\n",
            "[11/25/2024-09:02:19] [I] [TRT] ONNX IR version:  0.0.7\n",
            "[11/25/2024-09:02:19] [I] [TRT] Opset version:    13\n",
            "[11/25/2024-09:02:19] [I] [TRT] Producer name:    pytorch\n",
            "[11/25/2024-09:02:19] [I] [TRT] Producer version: 1.13.0\n",
            "[11/25/2024-09:02:19] [I] [TRT] Domain:           \n",
            "[11/25/2024-09:02:19] [I] [TRT] Model version:    0\n",
            "[11/25/2024-09:02:19] [I] [TRT] Doc string:       \n",
            "[11/25/2024-09:02:19] [I] [TRT] ----------------------------------------------------------------\n",
            "[11/25/2024-09:02:19] [I] Finished parsing network model. Parse time: 0.452601\n",
            "[11/25/2024-09:02:19] [W] Dynamic dimensions required for input: input_0, but no shapes were provided. Automatically overriding shape to: 1x3x224x224\n",
            "[11/25/2024-09:02:19] [I] Set shape of input tensor input_0 for optimization profile 0 to: MIN=1x3x224x224 OPT=1x3x224x224 MAX=1x3x224x224\n",
            "[11/25/2024-09:02:19] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best\n",
            "[11/25/2024-09:02:19] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[11/25/2024-09:02:19] [W] [TRT] Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.\n",
            "[11/25/2024-09:02:20] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[11/25/2024-09:02:20] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[11/25/2024-09:03:34] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
            "[11/25/2024-09:03:37] [I] [TRT] Total Host Persistent Memory: 247680\n",
            "[11/25/2024-09:03:37] [I] [TRT] Total Device Persistent Memory: 33792\n",
            "[11/25/2024-09:03:37] [I] [TRT] Total Scratch Memory: 6661120\n",
            "[11/25/2024-09:03:37] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 406 steps to complete.\n",
            "[11/25/2024-09:03:37] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 22.661ms to assign 6 blocks to 406 nodes requiring 13886976 bytes.\n",
            "[11/25/2024-09:03:37] [I] [TRT] Total Activation Memory: 13886464\n",
            "[11/25/2024-09:03:37] [I] [TRT] Total Weights Memory: 30226608\n",
            "[11/25/2024-09:03:37] [I] [TRT] Engine generation completed in 76.8348 seconds.\n",
            "[11/25/2024-09:03:37] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 295 MiB\n",
            "[11/25/2024-09:03:37] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 1769 MiB\n",
            "[11/25/2024-09:03:37] [I] Engine built in 77.5913 sec.\n",
            "[11/25/2024-09:03:37] [I] Created engine with size: 31.7403 MiB\n",
            "[11/25/2024-09:03:37] [I] [TRT] Loaded engine size: 31 MiB\n",
            "[11/25/2024-09:03:37] [I] Engine deserialized in 0.0296449 sec.\n",
            "[11/25/2024-09:03:37] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +14, now: CPU 0, GPU 42 (MiB)\n",
            "[11/25/2024-09:03:37] [I] Setting persistentCacheLimit to 0 bytes.\n",
            "[11/25/2024-09:03:37] [I] Created execution context with device memory size: 13.2432 MiB\n",
            "[11/25/2024-09:03:37] [I] Using random values for input input_0\n",
            "[11/25/2024-09:03:37] [I] Input binding for input_0 with dimensions 1x3x224x224 is created.\n",
            "[11/25/2024-09:03:37] [I] Output binding for output_0 with dimensions 1x12 is created.\n",
            "[11/25/2024-09:03:37] [I] Starting inference\n",
            "[11/25/2024-09:03:40] [I] Warmup completed 85 queries over 200 ms\n",
            "[11/25/2024-09:03:40] [I] Timing trace has 1506 queries over 3.0056 s\n",
            "[11/25/2024-09:03:40] [I] \n",
            "[11/25/2024-09:03:40] [I] === Trace details ===\n",
            "[11/25/2024-09:03:40] [I] Trace averages of 10 runs:\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.36449 ms - Host latency: 2.44399 ms (enqueue 1.18354 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.22735 ms - Host latency: 2.30616 ms (enqueue 1.18699 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93203 ms - Host latency: 2.00993 ms (enqueue 1.19154 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91689 ms - Host latency: 1.9943 ms (enqueue 1.1791 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91742 ms - Host latency: 1.99569 ms (enqueue 1.16928 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91719 ms - Host latency: 2.0051 ms (enqueue 1.25537 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91696 ms - Host latency: 1.99305 ms (enqueue 1.17958 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91623 ms - Host latency: 1.99344 ms (enqueue 1.1847 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91162 ms - Host latency: 1.9893 ms (enqueue 1.21401 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93014 ms - Host latency: 2.01645 ms (enqueue 1.30519 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93216 ms - Host latency: 2.01089 ms (enqueue 1.32162 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93146 ms - Host latency: 2.01799 ms (enqueue 1.22321 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93242 ms - Host latency: 2.0096 ms (enqueue 1.20953 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93015 ms - Host latency: 2.00843 ms (enqueue 1.19829 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91829 ms - Host latency: 2.00271 ms (enqueue 1.26147 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9174 ms - Host latency: 2.00241 ms (enqueue 1.34701 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91788 ms - Host latency: 1.99299 ms (enqueue 1.20161 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91906 ms - Host latency: 1.9954 ms (enqueue 1.20705 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91576 ms - Host latency: 1.99837 ms (enqueue 1.25432 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.90554 ms - Host latency: 1.9817 ms (enqueue 1.19393 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92618 ms - Host latency: 2.00356 ms (enqueue 1.19995 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.933 ms - Host latency: 2.00978 ms (enqueue 1.19432 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93186 ms - Host latency: 2.00939 ms (enqueue 1.20259 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93152 ms - Host latency: 2.00935 ms (enqueue 1.18351 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93105 ms - Host latency: 2.00768 ms (enqueue 1.18151 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92152 ms - Host latency: 1.99922 ms (enqueue 1.19265 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91656 ms - Host latency: 1.99249 ms (enqueue 1.202 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 3.49356 ms - Host latency: 3.59541 ms (enqueue 3.3382 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.03737 ms - Host latency: 2.21455 ms (enqueue 1.55849 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.86099 ms - Host latency: 1.943 ms (enqueue 1.20117 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.8892 ms - Host latency: 1.96536 ms (enqueue 1.22832 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91957 ms - Host latency: 2.00268 ms (enqueue 1.40709 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93224 ms - Host latency: 2.02368 ms (enqueue 1.80656 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93249 ms - Host latency: 2.01692 ms (enqueue 1.28218 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93191 ms - Host latency: 2.01345 ms (enqueue 1.19703 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93198 ms - Host latency: 2.00912 ms (enqueue 1.16323 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93228 ms - Host latency: 2.00825 ms (enqueue 1.16086 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9179 ms - Host latency: 1.99384 ms (enqueue 1.15937 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91735 ms - Host latency: 1.99404 ms (enqueue 1.2127 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9472 ms - Host latency: 2.02427 ms (enqueue 1.17208 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94738 ms - Host latency: 2.03598 ms (enqueue 1.38237 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.79908 ms - Host latency: 2.88145 ms (enqueue 2.76549 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93833 ms - Host latency: 2.01978 ms (enqueue 1.79205 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.8959 ms - Host latency: 1.97202 ms (enqueue 1.7212 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.95421 ms - Host latency: 2.03311 ms (enqueue 1.79985 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.85317 ms - Host latency: 3.25854 ms (enqueue 2.69149 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.89679 ms - Host latency: 1.9741 ms (enqueue 1.74982 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.67449 ms - Host latency: 2.78221 ms (enqueue 2.50878 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.87705 ms - Host latency: 1.95267 ms (enqueue 1.17448 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.88746 ms - Host latency: 1.96537 ms (enqueue 1.17438 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91359 ms - Host latency: 1.99017 ms (enqueue 1.15394 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93013 ms - Host latency: 2.00812 ms (enqueue 1.14702 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93159 ms - Host latency: 2.00919 ms (enqueue 1.15508 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93086 ms - Host latency: 2.00798 ms (enqueue 1.15406 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93229 ms - Host latency: 2.00989 ms (enqueue 1.13723 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93075 ms - Host latency: 2.00891 ms (enqueue 1.13938 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92461 ms - Host latency: 2.00236 ms (enqueue 1.13956 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92994 ms - Host latency: 2.01086 ms (enqueue 1.17592 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94686 ms - Host latency: 2.02579 ms (enqueue 1.19034 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94531 ms - Host latency: 2.02953 ms (enqueue 1.18604 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94647 ms - Host latency: 2.02975 ms (enqueue 1.22825 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93976 ms - Host latency: 2.01985 ms (enqueue 1.20531 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93376 ms - Host latency: 2.0124 ms (enqueue 1.2781 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93307 ms - Host latency: 2.00901 ms (enqueue 1.18394 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9318 ms - Host latency: 2.00964 ms (enqueue 1.17472 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92676 ms - Host latency: 2.00264 ms (enqueue 1.18855 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91595 ms - Host latency: 1.99287 ms (enqueue 1.16003 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91851 ms - Host latency: 1.99631 ms (enqueue 1.20303 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93464 ms - Host latency: 2.01278 ms (enqueue 1.17554 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93141 ms - Host latency: 2.00924 ms (enqueue 1.14948 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93169 ms - Host latency: 2.00792 ms (enqueue 1.14183 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 3.15215 ms - Host latency: 3.2397 ms (enqueue 2.80544 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.95608 ms - Host latency: 2.72194 ms (enqueue 1.73923 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.88091 ms - Host latency: 1.95614 ms (enqueue 1.61207 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.86776 ms - Host latency: 1.94629 ms (enqueue 1.208 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91053 ms - Host latency: 1.99094 ms (enqueue 1.16044 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93152 ms - Host latency: 2.00697 ms (enqueue 1.15566 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93226 ms - Host latency: 2.00856 ms (enqueue 1.22347 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93225 ms - Host latency: 2.01044 ms (enqueue 1.14368 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93088 ms - Host latency: 2.00752 ms (enqueue 1.15872 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93146 ms - Host latency: 2.00706 ms (enqueue 1.14242 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91526 ms - Host latency: 1.99409 ms (enqueue 1.46871 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9433 ms - Host latency: 2.02046 ms (enqueue 1.74237 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94607 ms - Host latency: 2.02439 ms (enqueue 1.33535 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94878 ms - Host latency: 2.02646 ms (enqueue 1.18461 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93331 ms - Host latency: 2.01038 ms (enqueue 1.16421 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93042 ms - Host latency: 2.0063 ms (enqueue 1.18162 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93151 ms - Host latency: 2.00891 ms (enqueue 1.17086 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9339 ms - Host latency: 2.00958 ms (enqueue 1.17706 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91873 ms - Host latency: 2.01288 ms (enqueue 1.26844 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9182 ms - Host latency: 1.99358 ms (enqueue 1.13821 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93624 ms - Host latency: 2.01398 ms (enqueue 1.15454 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9469 ms - Host latency: 2.02434 ms (enqueue 1.18872 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94575 ms - Host latency: 2.03464 ms (enqueue 1.19326 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94663 ms - Host latency: 2.02554 ms (enqueue 1.18611 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93767 ms - Host latency: 2.01797 ms (enqueue 1.2106 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93084 ms - Host latency: 2.01077 ms (enqueue 1.18818 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93125 ms - Host latency: 2.00986 ms (enqueue 1.20012 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93303 ms - Host latency: 2.01152 ms (enqueue 1.20151 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93167 ms - Host latency: 2.01941 ms (enqueue 1.21045 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92556 ms - Host latency: 2.01089 ms (enqueue 1.22214 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92449 ms - Host latency: 2.00642 ms (enqueue 1.18701 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94683 ms - Host latency: 2.02522 ms (enqueue 1.1908 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94668 ms - Host latency: 2.0239 ms (enqueue 1.17542 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94575 ms - Host latency: 2.02261 ms (enqueue 1.176 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94668 ms - Host latency: 2.02505 ms (enqueue 1.15483 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94348 ms - Host latency: 2.0198 ms (enqueue 1.13894 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93069 ms - Host latency: 2.00886 ms (enqueue 1.16377 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93035 ms - Host latency: 2.00791 ms (enqueue 1.18738 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93147 ms - Host latency: 2.01016 ms (enqueue 1.20852 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93064 ms - Host latency: 2.0084 ms (enqueue 1.17932 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93198 ms - Host latency: 2.00972 ms (enqueue 1.16938 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91729 ms - Host latency: 1.99648 ms (enqueue 1.19717 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93958 ms - Host latency: 2.01885 ms (enqueue 1.19807 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94614 ms - Host latency: 2.02617 ms (enqueue 1.21089 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94778 ms - Host latency: 2.02651 ms (enqueue 1.20771 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.97119 ms - Host latency: 2.04939 ms (enqueue 1.19165 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.00305 ms - Host latency: 2.08176 ms (enqueue 1.20493 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.01062 ms - Host latency: 2.08777 ms (enqueue 1.28059 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 2.00842 ms - Host latency: 2.08767 ms (enqueue 1.20896 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.99702 ms - Host latency: 2.08103 ms (enqueue 1.19258 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.98157 ms - Host latency: 2.0593 ms (enqueue 1.21108 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.95605 ms - Host latency: 2.03303 ms (enqueue 1.26951 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9468 ms - Host latency: 2.02561 ms (enqueue 1.16746 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94602 ms - Host latency: 2.02297 ms (enqueue 1.17258 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94712 ms - Host latency: 2.02512 ms (enqueue 1.17888 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93782 ms - Host latency: 2.01519 ms (enqueue 1.17729 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93159 ms - Host latency: 2.00928 ms (enqueue 1.16858 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93306 ms - Host latency: 2.01104 ms (enqueue 1.24775 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93433 ms - Host latency: 2.01123 ms (enqueue 1.17493 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93965 ms - Host latency: 2.01719 ms (enqueue 1.16865 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94687 ms - Host latency: 2.02397 ms (enqueue 1.17419 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94482 ms - Host latency: 2.02419 ms (enqueue 1.29543 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94685 ms - Host latency: 2.03569 ms (enqueue 1.26465 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94946 ms - Host latency: 2.03647 ms (enqueue 1.41936 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.95867 ms - Host latency: 2.03594 ms (enqueue 1.62942 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94775 ms - Host latency: 2.02617 ms (enqueue 1.48262 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92209 ms - Host latency: 1.99919 ms (enqueue 1.18958 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.91873 ms - Host latency: 1.99719 ms (enqueue 1.23398 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.92996 ms - Host latency: 2.00764 ms (enqueue 1.1675 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93191 ms - Host latency: 2.01069 ms (enqueue 1.2353 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93198 ms - Host latency: 2.01113 ms (enqueue 1.20759 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93352 ms - Host latency: 2.01233 ms (enqueue 1.17654 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93357 ms - Host latency: 2.01226 ms (enqueue 1.20142 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.9197 ms - Host latency: 1.99761 ms (enqueue 1.17593 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94358 ms - Host latency: 2.02629 ms (enqueue 1.19297 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94526 ms - Host latency: 2.02939 ms (enqueue 1.27451 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94705 ms - Host latency: 2.02424 ms (enqueue 1.15806 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.94749 ms - Host latency: 2.02581 ms (enqueue 1.21731 ms)\n",
            "[11/25/2024-09:03:40] [I] Average on 10 runs - GPU latency: 1.93792 ms - Host latency: 2.01582 ms (enqueue 1.17622 ms)\n",
            "[11/25/2024-09:03:40] [I] \n",
            "[11/25/2024-09:03:40] [I] === Performance summary ===\n",
            "[11/25/2024-09:03:40] [I] Throughput: 501.064 qps\n",
            "[11/25/2024-09:03:40] [I] Latency: min = 1.91821 ms, max = 14.1937 ms, mean = 2.06026 ms, median = 2.01025 ms, percentile(90%) = 2.03345 ms, percentile(95%) = 2.07642 ms, percentile(99%) = 2.44817 ms\n",
            "[11/25/2024-09:03:40] [I] Enqueue Time: min = 1.11169 ms, max = 14.104 ms, mean = 1.29228 ms, median = 1.18188 ms, percentile(90%) = 1.62085 ms, percentile(95%) = 1.74426 ms, percentile(99%) = 2.03406 ms\n",
            "[11/25/2024-09:03:40] [I] H2D Latency: min = 0.0661621 ms, max = 6.98242 ms, mean = 0.0807453 ms, median = 0.0720215 ms, percentile(90%) = 0.0761719 ms, percentile(95%) = 0.0803223 ms, percentile(99%) = 0.131226 ms\n",
            "[11/25/2024-09:03:40] [I] GPU Compute Time: min = 1.84436 ms, max = 14.119 ms, mean = 1.97344 ms, median = 1.93213 ms, percentile(90%) = 1.94971 ms, percentile(95%) = 1.98926 ms, percentile(99%) = 2.36554 ms\n",
            "[11/25/2024-09:03:41] [I] D2H Latency: min = 0.00360107 ms, max = 0.906982 ms, mean = 0.00607339 ms, median = 0.00512695 ms, percentile(90%) = 0.00689697 ms, percentile(95%) = 0.00732422 ms, percentile(99%) = 0.00817871 ms\n",
            "[11/25/2024-09:03:41] [I] Total Host Walltime: 3.0056 s\n",
            "[11/25/2024-09:03:41] [I] Total GPU Compute Time: 2.97201 s\n",
            "[11/25/2024-09:03:41] [W] * GPU compute time is unstable, with coefficient of variance = 28.4471%.\n",
            "[11/25/2024-09:03:41] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
            "[11/25/2024-09:03:41] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
            "[11/25/2024-09:03:41] [I] \n",
            "&&&& PASSED TensorRT.trtexec [TensorRT v100200] # /usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/dfan.onnx --saveEngine=./models/dfan.trt\n"
          ]
        }
      ],
      "source": [
        "!/usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/dfan.onnx  --saveEngine=./models/dfan.trt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/aider.onnx  --saveEngine=./models/aider.trt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab65uwe8b1il",
        "outputId": "13a47571-5387-4867-d4ec-284fd8c71cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&&&& RUNNING TensorRT.trtexec [TensorRT v100200] # /usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/aider.onnx --saveEngine=./models/aider.trt\n",
            "[11/25/2024-09:04:13] [I] === Model Options ===\n",
            "[11/25/2024-09:04:13] [I] Format: ONNX\n",
            "[11/25/2024-09:04:13] [I] Model: ./models/aider.onnx\n",
            "[11/25/2024-09:04:13] [I] Output:\n",
            "[11/25/2024-09:04:13] [I] === Build Options ===\n",
            "[11/25/2024-09:04:13] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
            "[11/25/2024-09:04:13] [I] avgTiming: 8\n",
            "[11/25/2024-09:04:13] [I] Precision: FP32+INT8\n",
            "[11/25/2024-09:04:13] [I] LayerPrecisions: \n",
            "[11/25/2024-09:04:13] [I] Layer Device Types: \n",
            "[11/25/2024-09:04:13] [I] Calibration: Dynamic\n",
            "[11/25/2024-09:04:13] [I] Refit: Disabled\n",
            "[11/25/2024-09:04:13] [I] Strip weights: Disabled\n",
            "[11/25/2024-09:04:13] [I] Version Compatible: Disabled\n",
            "[11/25/2024-09:04:13] [I] ONNX Plugin InstanceNorm: Disabled\n",
            "[11/25/2024-09:04:13] [I] TensorRT runtime: full\n",
            "[11/25/2024-09:04:13] [I] Lean DLL Path: \n",
            "[11/25/2024-09:04:13] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
            "[11/25/2024-09:04:13] [I] Exclude Lean Runtime: Disabled\n",
            "[11/25/2024-09:04:13] [I] Sparsity: Disabled\n",
            "[11/25/2024-09:04:13] [I] Safe mode: Disabled\n",
            "[11/25/2024-09:04:13] [I] Build DLA standalone loadable: Disabled\n",
            "[11/25/2024-09:04:13] [I] Allow GPU fallback for DLA: Disabled\n",
            "[11/25/2024-09:04:13] [I] DirectIO mode: Disabled\n",
            "[11/25/2024-09:04:13] [I] Restricted mode: Disabled\n",
            "[11/25/2024-09:04:13] [I] Skip inference: Disabled\n",
            "[11/25/2024-09:04:13] [I] Save engine: ./models/aider.trt\n",
            "[11/25/2024-09:04:13] [I] Load engine: \n",
            "[11/25/2024-09:04:13] [I] Profiling verbosity: 0\n",
            "[11/25/2024-09:04:13] [I] Tactic sources: Using default tactic sources\n",
            "[11/25/2024-09:04:13] [I] timingCacheMode: local\n",
            "[11/25/2024-09:04:13] [I] timingCacheFile: \n",
            "[11/25/2024-09:04:13] [I] Enable Compilation Cache: Enabled\n",
            "[11/25/2024-09:04:13] [I] errorOnTimingCacheMiss: Disabled\n",
            "[11/25/2024-09:04:13] [I] Preview Features: Use default preview flags.\n",
            "[11/25/2024-09:04:13] [I] MaxAuxStreams: -1\n",
            "[11/25/2024-09:04:13] [I] BuilderOptimizationLevel: -1\n",
            "[11/25/2024-09:04:13] [I] Calibration Profile Index: 0\n",
            "[11/25/2024-09:04:13] [I] Weight Streaming: Disabled\n",
            "[11/25/2024-09:04:13] [I] Runtime Platform: Same As Build\n",
            "[11/25/2024-09:04:13] [I] Debug Tensors: \n",
            "[11/25/2024-09:04:13] [I] Input(s)s format: fp32:CHW\n",
            "[11/25/2024-09:04:13] [I] Output(s)s format: fp32:CHW\n",
            "[11/25/2024-09:04:13] [I] Input build shapes: model\n",
            "[11/25/2024-09:04:13] [I] Input calibration shapes: model\n",
            "[11/25/2024-09:04:13] [I] === System Options ===\n",
            "[11/25/2024-09:04:13] [I] Device: 0\n",
            "[11/25/2024-09:04:13] [I] DLACore: \n",
            "[11/25/2024-09:04:13] [I] Plugins:\n",
            "[11/25/2024-09:04:13] [I] setPluginsToSerialize:\n",
            "[11/25/2024-09:04:13] [I] dynamicPlugins:\n",
            "[11/25/2024-09:04:13] [I] ignoreParsedPluginLibs: 0\n",
            "[11/25/2024-09:04:13] [I] \n",
            "[11/25/2024-09:04:13] [I] === Inference Options ===\n",
            "[11/25/2024-09:04:13] [I] Batch: Explicit\n",
            "[11/25/2024-09:04:13] [I] Input inference shapes: model\n",
            "[11/25/2024-09:04:13] [I] Iterations: 10\n",
            "[11/25/2024-09:04:13] [I] Duration: 3s (+ 200ms warm up)\n",
            "[11/25/2024-09:04:13] [I] Sleep time: 0ms\n",
            "[11/25/2024-09:04:13] [I] Idle time: 0ms\n",
            "[11/25/2024-09:04:13] [I] Inference Streams: 1\n",
            "[11/25/2024-09:04:13] [I] ExposeDMA: Disabled\n",
            "[11/25/2024-09:04:13] [I] Data transfers: Enabled\n",
            "[11/25/2024-09:04:13] [I] Spin-wait: Disabled\n",
            "[11/25/2024-09:04:13] [I] Multithreading: Disabled\n",
            "[11/25/2024-09:04:13] [I] CUDA Graph: Disabled\n",
            "[11/25/2024-09:04:13] [I] Separate profiling: Disabled\n",
            "[11/25/2024-09:04:13] [I] Time Deserialize: Disabled\n",
            "[11/25/2024-09:04:13] [I] Time Refit: Disabled\n",
            "[11/25/2024-09:04:13] [I] NVTX verbosity: 0\n",
            "[11/25/2024-09:04:13] [I] Persistent Cache Ratio: 0\n",
            "[11/25/2024-09:04:13] [I] Optimization Profile Index: 0\n",
            "[11/25/2024-09:04:13] [I] Weight Streaming Budget: 100.000000%\n",
            "[11/25/2024-09:04:13] [I] Inputs:\n",
            "[11/25/2024-09:04:13] [I] Debug Tensor Save Destinations:\n",
            "[11/25/2024-09:04:13] [I] === Reporting Options ===\n",
            "[11/25/2024-09:04:13] [I] Verbose: Disabled\n",
            "[11/25/2024-09:04:13] [I] Averages: 10 inferences\n",
            "[11/25/2024-09:04:13] [I] Percentiles: 90,95,99\n",
            "[11/25/2024-09:04:13] [I] Dump refittable layers:Disabled\n",
            "[11/25/2024-09:04:13] [I] Dump output: Disabled\n",
            "[11/25/2024-09:04:13] [I] Profile: Disabled\n",
            "[11/25/2024-09:04:13] [I] Export timing to JSON file: \n",
            "[11/25/2024-09:04:13] [I] Export output to JSON file: \n",
            "[11/25/2024-09:04:13] [I] Export profile to JSON file: \n",
            "[11/25/2024-09:04:13] [I] \n",
            "[11/25/2024-09:04:13] [I] === Device Information ===\n",
            "[11/25/2024-09:04:13] [I] Available Devices: \n",
            "[11/25/2024-09:04:13] [I]   Device 0: \"Tesla T4\" UUID: GPU-6f5efd2e-d728-47a1-a49f-d4d42c1a85af\n",
            "[11/25/2024-09:04:13] [I] Selected Device: Tesla T4\n",
            "[11/25/2024-09:04:13] [I] Selected Device ID: 0\n",
            "[11/25/2024-09:04:13] [I] Selected Device UUID: GPU-6f5efd2e-d728-47a1-a49f-d4d42c1a85af\n",
            "[11/25/2024-09:04:13] [I] Compute Capability: 7.5\n",
            "[11/25/2024-09:04:13] [I] SMs: 40\n",
            "[11/25/2024-09:04:13] [I] Device Global Memory: 15102 MiB\n",
            "[11/25/2024-09:04:13] [I] Shared Memory per SM: 64 KiB\n",
            "[11/25/2024-09:04:13] [I] Memory Bus Width: 256 bits (ECC enabled)\n",
            "[11/25/2024-09:04:13] [I] Application Compute Clock Rate: 1.59 GHz\n",
            "[11/25/2024-09:04:13] [I] Application Memory Clock Rate: 5.001 GHz\n",
            "[11/25/2024-09:04:13] [I] \n",
            "[11/25/2024-09:04:13] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
            "[11/25/2024-09:04:13] [I] \n",
            "[11/25/2024-09:04:13] [I] TensorRT version: 10.2.0\n",
            "[11/25/2024-09:04:13] [I] Loading standard plugins\n",
            "[11/25/2024-09:04:13] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 16, GPU 103 (MiB)\n",
            "[11/25/2024-09:04:15] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +904, GPU +180, now: CPU 1073, GPU 283 (MiB)\n",
            "[11/25/2024-09:04:15] [I] Start parsing network model.\n",
            "[11/25/2024-09:04:15] [I] [TRT] ----------------------------------------------------------------\n",
            "[11/25/2024-09:04:15] [I] [TRT] Input filename:   ./models/aider.onnx\n",
            "[11/25/2024-09:04:15] [I] [TRT] ONNX IR version:  0.0.7\n",
            "[11/25/2024-09:04:15] [I] [TRT] Opset version:    13\n",
            "[11/25/2024-09:04:15] [I] [TRT] Producer name:    pytorch\n",
            "[11/25/2024-09:04:15] [I] [TRT] Producer version: 1.13.0\n",
            "[11/25/2024-09:04:15] [I] [TRT] Domain:           \n",
            "[11/25/2024-09:04:15] [I] [TRT] Model version:    0\n",
            "[11/25/2024-09:04:15] [I] [TRT] Doc string:       \n",
            "[11/25/2024-09:04:15] [I] [TRT] ----------------------------------------------------------------\n",
            "[11/25/2024-09:04:15] [I] Finished parsing network model. Parse time: 0.304039\n",
            "[11/25/2024-09:04:15] [W] Dynamic dimensions required for input: input_0, but no shapes were provided. Automatically overriding shape to: 1x3x224x224\n",
            "[11/25/2024-09:04:15] [I] Set shape of input tensor input_0 for optimization profile 0 to: MIN=1x3x224x224 OPT=1x3x224x224 MAX=1x3x224x224\n",
            "[11/25/2024-09:04:15] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best\n",
            "[11/25/2024-09:04:15] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[11/25/2024-09:04:15] [W] [TRT] Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.\n",
            "[11/25/2024-09:04:16] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[11/25/2024-09:04:16] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[11/25/2024-09:05:27] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
            "[11/25/2024-09:05:29] [I] [TRT] Total Host Persistent Memory: 268320\n",
            "[11/25/2024-09:05:29] [I] [TRT] Total Device Persistent Memory: 33280\n",
            "[11/25/2024-09:05:29] [I] [TRT] Total Scratch Memory: 6661120\n",
            "[11/25/2024-09:05:29] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 400 steps to complete.\n",
            "[11/25/2024-09:05:29] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 26.0851ms to assign 6 blocks to 400 nodes requiring 13886976 bytes.\n",
            "[11/25/2024-09:05:29] [I] [TRT] Total Activation Memory: 13886464\n",
            "[11/25/2024-09:05:29] [I] [TRT] Total Weights Memory: 30148244\n",
            "[11/25/2024-09:05:29] [I] [TRT] Engine generation completed in 73.2966 seconds.\n",
            "[11/25/2024-09:05:29] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 295 MiB\n",
            "[11/25/2024-09:05:29] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 1775 MiB\n",
            "[11/25/2024-09:05:29] [I] Engine built in 74.0343 sec.\n",
            "[11/25/2024-09:05:29] [I] Created engine with size: 31.6719 MiB\n",
            "[11/25/2024-09:05:29] [I] [TRT] Loaded engine size: 31 MiB\n",
            "[11/25/2024-09:05:29] [I] Engine deserialized in 0.0293062 sec.\n",
            "[11/25/2024-09:05:29] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +14, now: CPU 0, GPU 42 (MiB)\n",
            "[11/25/2024-09:05:29] [I] Setting persistentCacheLimit to 0 bytes.\n",
            "[11/25/2024-09:05:29] [I] Created execution context with device memory size: 13.2432 MiB\n",
            "[11/25/2024-09:05:29] [I] Using random values for input input_0\n",
            "[11/25/2024-09:05:29] [I] Input binding for input_0 with dimensions 1x3x224x224 is created.\n",
            "[11/25/2024-09:05:29] [I] Output binding for output_0 with dimensions 1x5 is created.\n",
            "[11/25/2024-09:05:29] [I] Starting inference\n",
            "[11/25/2024-09:05:33] [I] Warmup completed 92 queries over 200 ms\n",
            "[11/25/2024-09:05:33] [I] Timing trace has 1501 queries over 3.00616 s\n",
            "[11/25/2024-09:05:33] [I] \n",
            "[11/25/2024-09:05:33] [I] === Trace details ===\n",
            "[11/25/2024-09:05:33] [I] Trace averages of 10 runs:\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.16787 ms - Host latency: 2.23726 ms (enqueue 1.38377 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.1689 ms - Host latency: 2.23705 ms (enqueue 1.41997 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.16813 ms - Host latency: 2.23404 ms (enqueue 1.17706 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.11316 ms - Host latency: 2.17855 ms (enqueue 1.24268 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.93935 ms - Host latency: 2.003 ms (enqueue 1.19226 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.93932 ms - Host latency: 2.00233 ms (enqueue 1.14403 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96479 ms - Host latency: 2.0273 ms (enqueue 1.16561 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98079 ms - Host latency: 2.04391 ms (enqueue 1.16242 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97938 ms - Host latency: 2.04214 ms (enqueue 1.15467 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98063 ms - Host latency: 2.04394 ms (enqueue 1.16434 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98119 ms - Host latency: 2.04438 ms (enqueue 1.16924 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97996 ms - Host latency: 2.0423 ms (enqueue 1.18371 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97036 ms - Host latency: 2.03196 ms (enqueue 1.17184 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97159 ms - Host latency: 2.03481 ms (enqueue 1.19653 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97056 ms - Host latency: 2.03278 ms (enqueue 1.18304 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97381 ms - Host latency: 2.0387 ms (enqueue 1.70556 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97098 ms - Host latency: 2.04135 ms (enqueue 1.50364 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.972 ms - Host latency: 2.03571 ms (enqueue 1.21326 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97167 ms - Host latency: 2.0345 ms (enqueue 1.16367 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9702 ms - Host latency: 2.03326 ms (enqueue 1.15835 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97066 ms - Host latency: 2.03267 ms (enqueue 1.19579 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97112 ms - Host latency: 2.03618 ms (enqueue 1.23043 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97037 ms - Host latency: 2.0321 ms (enqueue 1.15289 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97158 ms - Host latency: 2.03365 ms (enqueue 1.15786 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97266 ms - Host latency: 2.03652 ms (enqueue 1.16233 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97137 ms - Host latency: 2.04069 ms (enqueue 1.16923 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97177 ms - Host latency: 2.03701 ms (enqueue 1.31302 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97094 ms - Host latency: 2.03704 ms (enqueue 1.1989 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97123 ms - Host latency: 2.03623 ms (enqueue 1.19752 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97101 ms - Host latency: 2.03389 ms (enqueue 1.1532 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97195 ms - Host latency: 2.03494 ms (enqueue 1.15557 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97112 ms - Host latency: 2.03681 ms (enqueue 1.19268 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97183 ms - Host latency: 2.03683 ms (enqueue 1.18167 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97131 ms - Host latency: 2.03447 ms (enqueue 1.15952 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96968 ms - Host latency: 2.03365 ms (enqueue 1.23466 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96972 ms - Host latency: 2.0324 ms (enqueue 1.20867 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97114 ms - Host latency: 2.03547 ms (enqueue 1.23247 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97841 ms - Host latency: 2.05199 ms (enqueue 1.58878 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97021 ms - Host latency: 2.03211 ms (enqueue 1.28016 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96992 ms - Host latency: 2.03889 ms (enqueue 1.32621 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98674 ms - Host latency: 2.05012 ms (enqueue 1.21714 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.00705 ms - Host latency: 2.07067 ms (enqueue 1.19163 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02351 ms - Host latency: 2.08665 ms (enqueue 1.20947 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03987 ms - Host latency: 2.1035 ms (enqueue 1.19603 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04802 ms - Host latency: 2.1116 ms (enqueue 1.18202 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.06121 ms - Host latency: 2.12526 ms (enqueue 1.20825 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.07861 ms - Host latency: 2.14742 ms (enqueue 1.20702 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.08634 ms - Host latency: 2.14904 ms (enqueue 1.19265 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.08905 ms - Host latency: 2.15139 ms (enqueue 1.20311 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.07275 ms - Host latency: 2.13633 ms (enqueue 1.17786 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.05223 ms - Host latency: 2.11506 ms (enqueue 1.1828 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03291 ms - Host latency: 2.10411 ms (enqueue 1.30061 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.01696 ms - Host latency: 2.08342 ms (enqueue 1.23802 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.01257 ms - Host latency: 2.08096 ms (enqueue 1.23757 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.00072 ms - Host latency: 2.07256 ms (enqueue 1.60032 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99645 ms - Host latency: 2.0593 ms (enqueue 1.39479 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99851 ms - Host latency: 2.06343 ms (enqueue 1.17053 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99744 ms - Host latency: 2.06119 ms (enqueue 1.17205 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98521 ms - Host latency: 2.0535 ms (enqueue 1.2255 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98215 ms - Host latency: 2.04586 ms (enqueue 1.1812 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9802 ms - Host latency: 2.04386 ms (enqueue 1.29893 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98202 ms - Host latency: 2.04594 ms (enqueue 1.25016 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98341 ms - Host latency: 2.0537 ms (enqueue 1.29916 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97841 ms - Host latency: 2.04874 ms (enqueue 1.21729 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9718 ms - Host latency: 2.03595 ms (enqueue 1.19982 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97159 ms - Host latency: 2.03512 ms (enqueue 1.15371 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97253 ms - Host latency: 2.03613 ms (enqueue 1.28651 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97285 ms - Host latency: 2.04801 ms (enqueue 1.62878 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97073 ms - Host latency: 2.04686 ms (enqueue 1.19856 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97047 ms - Host latency: 2.03439 ms (enqueue 1.18013 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97086 ms - Host latency: 2.03306 ms (enqueue 1.15336 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97028 ms - Host latency: 2.03265 ms (enqueue 1.15735 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97002 ms - Host latency: 2.0319 ms (enqueue 1.149 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96946 ms - Host latency: 2.03204 ms (enqueue 1.14327 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9849 ms - Host latency: 2.04866 ms (enqueue 1.1611 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99583 ms - Host latency: 2.06321 ms (enqueue 1.20773 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99702 ms - Host latency: 2.06257 ms (enqueue 1.30039 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99698 ms - Host latency: 2.06251 ms (enqueue 1.19541 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98986 ms - Host latency: 2.06248 ms (enqueue 1.22354 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97952 ms - Host latency: 2.04336 ms (enqueue 1.19541 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98059 ms - Host latency: 2.04968 ms (enqueue 1.18479 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97958 ms - Host latency: 2.04427 ms (enqueue 1.21263 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98048 ms - Host latency: 2.04232 ms (enqueue 1.15193 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97786 ms - Host latency: 2.04077 ms (enqueue 1.18495 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97164 ms - Host latency: 2.0432 ms (enqueue 1.20419 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96865 ms - Host latency: 2.03069 ms (enqueue 1.14954 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97253 ms - Host latency: 2.03463 ms (enqueue 1.16505 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9712 ms - Host latency: 2.04193 ms (enqueue 1.28434 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9812 ms - Host latency: 2.04604 ms (enqueue 1.26328 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.00315 ms - Host latency: 2.07816 ms (enqueue 1.37806 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.01359 ms - Host latency: 2.08456 ms (enqueue 1.24884 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02051 ms - Host latency: 2.0871 ms (enqueue 1.22085 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03719 ms - Host latency: 2.10326 ms (enqueue 1.22086 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04634 ms - Host latency: 2.11475 ms (enqueue 1.16362 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04966 ms - Host latency: 2.11252 ms (enqueue 1.1646 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04824 ms - Host latency: 2.11069 ms (enqueue 1.14568 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04741 ms - Host latency: 2.11096 ms (enqueue 1.15105 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04336 ms - Host latency: 2.10642 ms (enqueue 1.14482 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03428 ms - Host latency: 2.09795 ms (enqueue 1.14067 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03425 ms - Host latency: 2.09756 ms (enqueue 1.16829 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.0311 ms - Host latency: 2.09495 ms (enqueue 1.14338 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02834 ms - Host latency: 2.09917 ms (enqueue 1.25896 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03027 ms - Host latency: 2.09998 ms (enqueue 1.19958 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02813 ms - Host latency: 2.09609 ms (enqueue 1.20786 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02009 ms - Host latency: 2.08872 ms (enqueue 1.21689 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.00334 ms - Host latency: 2.07761 ms (enqueue 1.25474 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99644 ms - Host latency: 2.06509 ms (enqueue 1.21252 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99551 ms - Host latency: 2.0668 ms (enqueue 1.19856 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99797 ms - Host latency: 2.0688 ms (enqueue 1.22883 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98906 ms - Host latency: 2.05642 ms (enqueue 1.21743 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98093 ms - Host latency: 2.04807 ms (enqueue 1.19626 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98164 ms - Host latency: 2.04746 ms (enqueue 1.22246 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97937 ms - Host latency: 2.04316 ms (enqueue 1.22529 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97874 ms - Host latency: 2.04368 ms (enqueue 1.22998 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97842 ms - Host latency: 2.05837 ms (enqueue 1.23765 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96982 ms - Host latency: 2.04053 ms (enqueue 1.23879 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97085 ms - Host latency: 2.0345 ms (enqueue 1.22349 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97087 ms - Host latency: 2.03972 ms (enqueue 1.26162 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97134 ms - Host latency: 2.0594 ms (enqueue 1.67754 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.96902 ms - Host latency: 2.0324 ms (enqueue 1.26536 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9698 ms - Host latency: 2.03547 ms (enqueue 1.21663 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.9802 ms - Host latency: 2.04304 ms (enqueue 1.15583 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99739 ms - Host latency: 2.06028 ms (enqueue 1.14902 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99578 ms - Host latency: 2.05791 ms (enqueue 1.14988 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99702 ms - Host latency: 2.06023 ms (enqueue 1.15317 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99744 ms - Host latency: 2.06035 ms (enqueue 1.14658 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99038 ms - Host latency: 2.06536 ms (enqueue 1.24253 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98235 ms - Host latency: 2.05203 ms (enqueue 1.17817 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98147 ms - Host latency: 2.04854 ms (enqueue 1.24216 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98191 ms - Host latency: 2.04961 ms (enqueue 1.24602 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.98042 ms - Host latency: 2.04617 ms (enqueue 1.2113 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97944 ms - Host latency: 2.04473 ms (enqueue 1.20447 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97114 ms - Host latency: 2.03298 ms (enqueue 1.14866 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97019 ms - Host latency: 2.0333 ms (enqueue 1.1916 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.97517 ms - Host latency: 2.03828 ms (enqueue 1.14529 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99707 ms - Host latency: 2.05991 ms (enqueue 1.16069 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99778 ms - Host latency: 2.06143 ms (enqueue 1.1533 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99878 ms - Host latency: 2.06296 ms (enqueue 1.20869 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99775 ms - Host latency: 2.06074 ms (enqueue 1.14685 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 1.99807 ms - Host latency: 2.06162 ms (enqueue 1.15481 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.01504 ms - Host latency: 2.07839 ms (enqueue 1.17502 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.01265 ms - Host latency: 2.07566 ms (enqueue 1.16467 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.01562 ms - Host latency: 2.07905 ms (enqueue 1.1915 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.0302 ms - Host latency: 2.09556 ms (enqueue 1.17083 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02925 ms - Host latency: 2.09192 ms (enqueue 1.24409 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02998 ms - Host latency: 2.09299 ms (enqueue 1.18604 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.03086 ms - Host latency: 2.09458 ms (enqueue 1.16599 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02803 ms - Host latency: 2.09185 ms (enqueue 1.17 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.02534 ms - Host latency: 2.08877 ms (enqueue 1.16917 ms)\n",
            "[11/25/2024-09:05:33] [I] Average on 10 runs - GPU latency: 2.04656 ms - Host latency: 2.1105 ms (enqueue 1.16052 ms)\n",
            "[11/25/2024-09:05:33] [I] \n",
            "[11/25/2024-09:05:33] [I] === Performance summary ===\n",
            "[11/25/2024-09:05:33] [I] Throughput: 499.307 qps\n",
            "[11/25/2024-09:05:33] [I] Latency: min = 1.99316 ms, max = 2.25977 ms, mean = 2.06394 ms, median = 2.04834 ms, percentile(90%) = 2.10974 ms, percentile(95%) = 2.13257 ms, percentile(99%) = 2.23535 ms\n",
            "[11/25/2024-09:05:33] [I] Enqueue Time: min = 1.1084 ms, max = 3.44043 ms, mean = 1.21933 ms, median = 1.17924 ms, percentile(90%) = 1.28113 ms, percentile(95%) = 1.50317 ms, percentile(99%) = 1.74561 ms\n",
            "[11/25/2024-09:05:33] [I] H2D Latency: min = 0.0551758 ms, max = 0.130737 ms, mean = 0.0602365 ms, median = 0.0581055 ms, percentile(90%) = 0.0639648 ms, percentile(95%) = 0.0664062 ms, percentile(99%) = 0.112549 ms\n",
            "[11/25/2024-09:05:33] [I] GPU Compute Time: min = 1.93112 ms, max = 2.17604 ms, mean = 1.99833 ms, median = 1.98242 ms, percentile(90%) = 2.04602 ms, percentile(95%) = 2.06653 ms, percentile(99%) = 2.16882 ms\n",
            "[11/25/2024-09:05:33] [I] D2H Latency: min = 0.00366211 ms, max = 0.0131836 ms, mean = 0.005376 ms, median = 0.00512695 ms, percentile(90%) = 0.00683594 ms, percentile(95%) = 0.00720215 ms, percentile(99%) = 0.0078125 ms\n",
            "[11/25/2024-09:05:33] [I] Total Host Walltime: 3.00616 s\n",
            "[11/25/2024-09:05:33] [I] Total GPU Compute Time: 2.9995 s\n",
            "[11/25/2024-09:05:33] [W] * GPU compute time is unstable, with coefficient of variance = 1.9899%.\n",
            "[11/25/2024-09:05:33] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
            "[11/25/2024-09:05:33] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
            "[11/25/2024-09:05:33] [I] \n",
            "&&&& PASSED TensorRT.trtexec [TensorRT v100200] # /usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/aider.onnx --saveEngine=./models/aider.trt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/disastereye.onnx  --saveEngine=./models/disastereye.trt"
      ],
      "metadata": {
        "id": "DZyKHlttb4RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763abe5c-25cf-4024-d933-5acea95ffe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&&&& RUNNING TensorRT.trtexec [TensorRT v100200] # /usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/disastereye.onnx --saveEngine=./models/disastereye.trt\n",
            "[11/25/2024-09:05:33] [I] === Model Options ===\n",
            "[11/25/2024-09:05:33] [I] Format: ONNX\n",
            "[11/25/2024-09:05:33] [I] Model: ./models/disastereye.onnx\n",
            "[11/25/2024-09:05:33] [I] Output:\n",
            "[11/25/2024-09:05:33] [I] === Build Options ===\n",
            "[11/25/2024-09:05:33] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
            "[11/25/2024-09:05:33] [I] avgTiming: 8\n",
            "[11/25/2024-09:05:33] [I] Precision: FP32+INT8\n",
            "[11/25/2024-09:05:33] [I] LayerPrecisions: \n",
            "[11/25/2024-09:05:33] [I] Layer Device Types: \n",
            "[11/25/2024-09:05:33] [I] Calibration: Dynamic\n",
            "[11/25/2024-09:05:33] [I] Refit: Disabled\n",
            "[11/25/2024-09:05:33] [I] Strip weights: Disabled\n",
            "[11/25/2024-09:05:33] [I] Version Compatible: Disabled\n",
            "[11/25/2024-09:05:33] [I] ONNX Plugin InstanceNorm: Disabled\n",
            "[11/25/2024-09:05:33] [I] TensorRT runtime: full\n",
            "[11/25/2024-09:05:33] [I] Lean DLL Path: \n",
            "[11/25/2024-09:05:33] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
            "[11/25/2024-09:05:33] [I] Exclude Lean Runtime: Disabled\n",
            "[11/25/2024-09:05:33] [I] Sparsity: Disabled\n",
            "[11/25/2024-09:05:33] [I] Safe mode: Disabled\n",
            "[11/25/2024-09:05:33] [I] Build DLA standalone loadable: Disabled\n",
            "[11/25/2024-09:05:33] [I] Allow GPU fallback for DLA: Disabled\n",
            "[11/25/2024-09:05:33] [I] DirectIO mode: Disabled\n",
            "[11/25/2024-09:05:33] [I] Restricted mode: Disabled\n",
            "[11/25/2024-09:05:33] [I] Skip inference: Disabled\n",
            "[11/25/2024-09:05:33] [I] Save engine: ./models/disastereye.trt\n",
            "[11/25/2024-09:05:33] [I] Load engine: \n",
            "[11/25/2024-09:05:33] [I] Profiling verbosity: 0\n",
            "[11/25/2024-09:05:33] [I] Tactic sources: Using default tactic sources\n",
            "[11/25/2024-09:05:33] [I] timingCacheMode: local\n",
            "[11/25/2024-09:05:33] [I] timingCacheFile: \n",
            "[11/25/2024-09:05:33] [I] Enable Compilation Cache: Enabled\n",
            "[11/25/2024-09:05:33] [I] errorOnTimingCacheMiss: Disabled\n",
            "[11/25/2024-09:05:33] [I] Preview Features: Use default preview flags.\n",
            "[11/25/2024-09:05:33] [I] MaxAuxStreams: -1\n",
            "[11/25/2024-09:05:33] [I] BuilderOptimizationLevel: -1\n",
            "[11/25/2024-09:05:33] [I] Calibration Profile Index: 0\n",
            "[11/25/2024-09:05:33] [I] Weight Streaming: Disabled\n",
            "[11/25/2024-09:05:33] [I] Runtime Platform: Same As Build\n",
            "[11/25/2024-09:05:33] [I] Debug Tensors: \n",
            "[11/25/2024-09:05:33] [I] Input(s)s format: fp32:CHW\n",
            "[11/25/2024-09:05:33] [I] Output(s)s format: fp32:CHW\n",
            "[11/25/2024-09:05:33] [I] Input build shapes: model\n",
            "[11/25/2024-09:05:33] [I] Input calibration shapes: model\n",
            "[11/25/2024-09:05:33] [I] === System Options ===\n",
            "[11/25/2024-09:05:33] [I] Device: 0\n",
            "[11/25/2024-09:05:33] [I] DLACore: \n",
            "[11/25/2024-09:05:33] [I] Plugins:\n",
            "[11/25/2024-09:05:33] [I] setPluginsToSerialize:\n",
            "[11/25/2024-09:05:33] [I] dynamicPlugins:\n",
            "[11/25/2024-09:05:33] [I] ignoreParsedPluginLibs: 0\n",
            "[11/25/2024-09:05:33] [I] \n",
            "[11/25/2024-09:05:33] [I] === Inference Options ===\n",
            "[11/25/2024-09:05:33] [I] Batch: Explicit\n",
            "[11/25/2024-09:05:33] [I] Input inference shapes: model\n",
            "[11/25/2024-09:05:33] [I] Iterations: 10\n",
            "[11/25/2024-09:05:33] [I] Duration: 3s (+ 200ms warm up)\n",
            "[11/25/2024-09:05:33] [I] Sleep time: 0ms\n",
            "[11/25/2024-09:05:33] [I] Idle time: 0ms\n",
            "[11/25/2024-09:05:33] [I] Inference Streams: 1\n",
            "[11/25/2024-09:05:33] [I] ExposeDMA: Disabled\n",
            "[11/25/2024-09:05:33] [I] Data transfers: Enabled\n",
            "[11/25/2024-09:05:33] [I] Spin-wait: Disabled\n",
            "[11/25/2024-09:05:33] [I] Multithreading: Disabled\n",
            "[11/25/2024-09:05:33] [I] CUDA Graph: Disabled\n",
            "[11/25/2024-09:05:33] [I] Separate profiling: Disabled\n",
            "[11/25/2024-09:05:33] [I] Time Deserialize: Disabled\n",
            "[11/25/2024-09:05:33] [I] Time Refit: Disabled\n",
            "[11/25/2024-09:05:33] [I] NVTX verbosity: 0\n",
            "[11/25/2024-09:05:33] [I] Persistent Cache Ratio: 0\n",
            "[11/25/2024-09:05:33] [I] Optimization Profile Index: 0\n",
            "[11/25/2024-09:05:33] [I] Weight Streaming Budget: 100.000000%\n",
            "[11/25/2024-09:05:33] [I] Inputs:\n",
            "[11/25/2024-09:05:33] [I] Debug Tensor Save Destinations:\n",
            "[11/25/2024-09:05:33] [I] === Reporting Options ===\n",
            "[11/25/2024-09:05:33] [I] Verbose: Disabled\n",
            "[11/25/2024-09:05:33] [I] Averages: 10 inferences\n",
            "[11/25/2024-09:05:33] [I] Percentiles: 90,95,99\n",
            "[11/25/2024-09:05:33] [I] Dump refittable layers:Disabled\n",
            "[11/25/2024-09:05:33] [I] Dump output: Disabled\n",
            "[11/25/2024-09:05:33] [I] Profile: Disabled\n",
            "[11/25/2024-09:05:33] [I] Export timing to JSON file: \n",
            "[11/25/2024-09:05:33] [I] Export output to JSON file: \n",
            "[11/25/2024-09:05:33] [I] Export profile to JSON file: \n",
            "[11/25/2024-09:05:33] [I] \n",
            "[11/25/2024-09:05:33] [I] === Device Information ===\n",
            "[11/25/2024-09:05:33] [I] Available Devices: \n",
            "[11/25/2024-09:05:33] [I]   Device 0: \"Tesla T4\" UUID: GPU-6f5efd2e-d728-47a1-a49f-d4d42c1a85af\n",
            "[11/25/2024-09:05:33] [I] Selected Device: Tesla T4\n",
            "[11/25/2024-09:05:33] [I] Selected Device ID: 0\n",
            "[11/25/2024-09:05:33] [I] Selected Device UUID: GPU-6f5efd2e-d728-47a1-a49f-d4d42c1a85af\n",
            "[11/25/2024-09:05:33] [I] Compute Capability: 7.5\n",
            "[11/25/2024-09:05:33] [I] SMs: 40\n",
            "[11/25/2024-09:05:33] [I] Device Global Memory: 15102 MiB\n",
            "[11/25/2024-09:05:33] [I] Shared Memory per SM: 64 KiB\n",
            "[11/25/2024-09:05:33] [I] Memory Bus Width: 256 bits (ECC enabled)\n",
            "[11/25/2024-09:05:33] [I] Application Compute Clock Rate: 1.59 GHz\n",
            "[11/25/2024-09:05:33] [I] Application Memory Clock Rate: 5.001 GHz\n",
            "[11/25/2024-09:05:33] [I] \n",
            "[11/25/2024-09:05:33] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
            "[11/25/2024-09:05:33] [I] \n",
            "[11/25/2024-09:05:33] [I] TensorRT version: 10.2.0\n",
            "[11/25/2024-09:05:33] [I] Loading standard plugins\n",
            "[11/25/2024-09:05:33] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 16, GPU 103 (MiB)\n",
            "[11/25/2024-09:05:35] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +904, GPU +180, now: CPU 1073, GPU 283 (MiB)\n",
            "[11/25/2024-09:05:35] [I] Start parsing network model.\n",
            "[11/25/2024-09:05:35] [I] [TRT] ----------------------------------------------------------------\n",
            "[11/25/2024-09:05:35] [I] [TRT] Input filename:   ./models/disastereye.onnx\n",
            "[11/25/2024-09:05:35] [I] [TRT] ONNX IR version:  0.0.7\n",
            "[11/25/2024-09:05:35] [I] [TRT] Opset version:    13\n",
            "[11/25/2024-09:05:35] [I] [TRT] Producer name:    pytorch\n",
            "[11/25/2024-09:05:35] [I] [TRT] Producer version: 1.13.0\n",
            "[11/25/2024-09:05:35] [I] [TRT] Domain:           \n",
            "[11/25/2024-09:05:35] [I] [TRT] Model version:    0\n",
            "[11/25/2024-09:05:35] [I] [TRT] Doc string:       \n",
            "[11/25/2024-09:05:35] [I] [TRT] ----------------------------------------------------------------\n",
            "[11/25/2024-09:05:35] [I] Finished parsing network model. Parse time: 0.390583\n",
            "[11/25/2024-09:05:35] [W] Dynamic dimensions required for input: input_0, but no shapes were provided. Automatically overriding shape to: 1x3x224x224\n",
            "[11/25/2024-09:05:35] [I] Set shape of input tensor input_0 for optimization profile 0 to: MIN=1x3x224x224 OPT=1x3x224x224 MAX=1x3x224x224\n",
            "[11/25/2024-09:05:35] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best\n",
            "[11/25/2024-09:05:35] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[11/25/2024-09:05:35] [W] [TRT] Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.\n",
            "[11/25/2024-09:05:36] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[11/25/2024-09:05:36] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[11/25/2024-09:06:46] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
            "[11/25/2024-09:06:48] [I] [TRT] Total Host Persistent Memory: 260832\n",
            "[11/25/2024-09:06:48] [I] [TRT] Total Device Persistent Memory: 30720\n",
            "[11/25/2024-09:06:48] [I] [TRT] Total Scratch Memory: 6661120\n",
            "[11/25/2024-09:06:48] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 402 steps to complete.\n",
            "[11/25/2024-09:06:48] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 22.6049ms to assign 6 blocks to 402 nodes requiring 13886976 bytes.\n",
            "[11/25/2024-09:06:48] [I] [TRT] Total Activation Memory: 13886464\n",
            "[11/25/2024-09:06:48] [I] [TRT] Total Weights Memory: 30157472\n",
            "[11/25/2024-09:06:48] [I] [TRT] Engine generation completed in 72.0561 seconds.\n",
            "[11/25/2024-09:06:48] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 295 MiB\n",
            "[11/25/2024-09:06:48] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 1771 MiB\n",
            "[11/25/2024-09:06:48] [I] Engine built in 73.079 sec.\n",
            "[11/25/2024-09:06:48] [I] Created engine with size: 31.8097 MiB\n",
            "[11/25/2024-09:06:49] [I] [TRT] Loaded engine size: 31 MiB\n",
            "[11/25/2024-09:06:49] [I] Engine deserialized in 0.0298969 sec.\n",
            "[11/25/2024-09:06:49] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +14, now: CPU 0, GPU 42 (MiB)\n",
            "[11/25/2024-09:06:49] [I] Setting persistentCacheLimit to 0 bytes.\n",
            "[11/25/2024-09:06:49] [I] Created execution context with device memory size: 13.2432 MiB\n",
            "[11/25/2024-09:06:49] [I] Using random values for input input_0\n",
            "[11/25/2024-09:06:49] [I] Input binding for input_0 with dimensions 1x3x224x224 is created.\n",
            "[11/25/2024-09:06:49] [I] Output binding for output_0 with dimensions 1x8 is created.\n",
            "[11/25/2024-09:06:49] [I] Starting inference\n",
            "[11/25/2024-09:06:52] [I] Warmup completed 95 queries over 200 ms\n",
            "[11/25/2024-09:06:52] [I] Timing trace has 1464 queries over 3.00629 s\n",
            "[11/25/2024-09:06:52] [I] \n",
            "[11/25/2024-09:06:52] [I] === Trace details ===\n",
            "[11/25/2024-09:06:52] [I] Trace averages of 10 runs:\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02096 ms - Host latency: 2.0863 ms (enqueue 1.18697 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02111 ms - Host latency: 2.08691 ms (enqueue 1.19099 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01981 ms - Host latency: 2.08636 ms (enqueue 1.15881 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01213 ms - Host latency: 2.08204 ms (enqueue 1.26219 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01667 ms - Host latency: 2.08133 ms (enqueue 1.20713 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03849 ms - Host latency: 2.11199 ms (enqueue 1.19179 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03797 ms - Host latency: 2.10844 ms (enqueue 1.19091 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0381 ms - Host latency: 2.10452 ms (enqueue 1.17821 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02909 ms - Host latency: 2.0969 ms (enqueue 1.20024 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02072 ms - Host latency: 2.08712 ms (enqueue 1.15908 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0201 ms - Host latency: 2.08481 ms (enqueue 1.22639 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02015 ms - Host latency: 2.09424 ms (enqueue 1.21908 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0193 ms - Host latency: 2.09203 ms (enqueue 1.31262 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01135 ms - Host latency: 2.10321 ms (enqueue 1.70694 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02117 ms - Host latency: 2.08615 ms (enqueue 1.21175 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03723 ms - Host latency: 2.10352 ms (enqueue 1.20507 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03644 ms - Host latency: 2.10181 ms (enqueue 1.26781 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03633 ms - Host latency: 2.10198 ms (enqueue 1.27398 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03713 ms - Host latency: 2.10994 ms (enqueue 1.20941 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02652 ms - Host latency: 2.09156 ms (enqueue 1.1567 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01881 ms - Host latency: 2.08398 ms (enqueue 1.14822 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01871 ms - Host latency: 2.08451 ms (enqueue 1.14705 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02014 ms - Host latency: 2.08505 ms (enqueue 1.1358 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02002 ms - Host latency: 2.08635 ms (enqueue 1.22154 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01022 ms - Host latency: 2.07577 ms (enqueue 1.13627 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0248 ms - Host latency: 2.09037 ms (enqueue 1.14935 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03829 ms - Host latency: 2.10453 ms (enqueue 1.17844 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03878 ms - Host latency: 2.10727 ms (enqueue 1.19319 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0376 ms - Host latency: 2.10524 ms (enqueue 1.15321 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03682 ms - Host latency: 2.10273 ms (enqueue 1.1909 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0254 ms - Host latency: 2.0915 ms (enqueue 1.1891 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02047 ms - Host latency: 2.08723 ms (enqueue 1.16462 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01817 ms - Host latency: 2.09117 ms (enqueue 1.22856 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.04636 ms - Host latency: 2.11887 ms (enqueue 1.21267 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.08984 ms - Host latency: 2.15891 ms (enqueue 1.21578 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10172 ms - Host latency: 2.17265 ms (enqueue 1.15795 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10315 ms - Host latency: 2.16833 ms (enqueue 1.13582 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10084 ms - Host latency: 2.1662 ms (enqueue 1.15125 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10182 ms - Host latency: 2.19413 ms (enqueue 1.22575 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07791 ms - Host latency: 2.14539 ms (enqueue 1.19567 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.13691 ms - Host latency: 2.20522 ms (enqueue 1.20685 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.13557 ms - Host latency: 2.20328 ms (enqueue 1.19446 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.1073 ms - Host latency: 2.17252 ms (enqueue 1.14552 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.09733 ms - Host latency: 2.16333 ms (enqueue 1.20203 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07556 ms - Host latency: 2.14298 ms (enqueue 1.20438 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07657 ms - Host latency: 2.14291 ms (enqueue 1.18562 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07202 ms - Host latency: 2.13922 ms (enqueue 1.22217 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0566 ms - Host latency: 2.12299 ms (enqueue 1.2124 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05657 ms - Host latency: 2.12203 ms (enqueue 1.16829 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05131 ms - Host latency: 2.11613 ms (enqueue 1.15997 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03739 ms - Host latency: 2.1162 ms (enqueue 1.23215 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03781 ms - Host latency: 2.10459 ms (enqueue 1.1967 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03895 ms - Host latency: 2.11674 ms (enqueue 1.29128 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03662 ms - Host latency: 2.10326 ms (enqueue 1.18866 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03173 ms - Host latency: 2.10034 ms (enqueue 1.19185 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0188 ms - Host latency: 2.08523 ms (enqueue 1.18911 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03534 ms - Host latency: 2.1082 ms (enqueue 1.19745 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05676 ms - Host latency: 2.1254 ms (enqueue 1.1999 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.04856 ms - Host latency: 2.11536 ms (enqueue 1.18326 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03752 ms - Host latency: 2.10314 ms (enqueue 1.24382 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03702 ms - Host latency: 2.10759 ms (enqueue 1.18632 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03907 ms - Host latency: 2.10513 ms (enqueue 1.204 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02877 ms - Host latency: 2.1005 ms (enqueue 1.35089 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02002 ms - Host latency: 2.10023 ms (enqueue 1.64506 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01974 ms - Host latency: 2.08533 ms (enqueue 1.15404 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02156 ms - Host latency: 2.08595 ms (enqueue 1.13038 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01959 ms - Host latency: 2.08424 ms (enqueue 1.13611 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0109 ms - Host latency: 2.0762 ms (enqueue 1.13827 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02201 ms - Host latency: 2.08584 ms (enqueue 1.12222 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03781 ms - Host latency: 2.10238 ms (enqueue 1.13003 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03822 ms - Host latency: 2.10314 ms (enqueue 1.12858 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03815 ms - Host latency: 2.10225 ms (enqueue 1.13082 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03914 ms - Host latency: 2.10573 ms (enqueue 1.1996 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02456 ms - Host latency: 2.09008 ms (enqueue 1.16835 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02051 ms - Host latency: 2.08816 ms (enqueue 1.20068 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02087 ms - Host latency: 2.08617 ms (enqueue 1.22711 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02118 ms - Host latency: 2.09795 ms (enqueue 1.22743 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02203 ms - Host latency: 2.08634 ms (enqueue 1.20056 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03274 ms - Host latency: 2.09717 ms (enqueue 1.20933 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05067 ms - Host latency: 2.11707 ms (enqueue 1.21371 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05656 ms - Host latency: 2.12396 ms (enqueue 1.21809 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05743 ms - Host latency: 2.1256 ms (enqueue 1.26321 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05695 ms - Host latency: 2.12332 ms (enqueue 1.20811 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07249 ms - Host latency: 2.13994 ms (enqueue 1.23092 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07891 ms - Host latency: 2.14956 ms (enqueue 1.22075 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07836 ms - Host latency: 2.14424 ms (enqueue 1.20905 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07943 ms - Host latency: 2.1467 ms (enqueue 1.2281 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10039 ms - Host latency: 2.17122 ms (enqueue 1.22234 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10232 ms - Host latency: 2.17313 ms (enqueue 1.18823 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10164 ms - Host latency: 2.1682 ms (enqueue 1.1933 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.09802 ms - Host latency: 2.1691 ms (enqueue 1.18883 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07615 ms - Host latency: 2.14094 ms (enqueue 1.14875 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07656 ms - Host latency: 2.1418 ms (enqueue 1.1762 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07761 ms - Host latency: 2.14233 ms (enqueue 1.13975 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07234 ms - Host latency: 2.13726 ms (enqueue 1.20593 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0575 ms - Host latency: 2.12981 ms (enqueue 1.19973 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0564 ms - Host latency: 2.12432 ms (enqueue 1.20264 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05481 ms - Host latency: 2.12073 ms (enqueue 1.19758 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05129 ms - Host latency: 2.11804 ms (enqueue 1.21438 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03677 ms - Host latency: 2.10369 ms (enqueue 1.19829 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03813 ms - Host latency: 2.10378 ms (enqueue 1.16975 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0366 ms - Host latency: 2.10945 ms (enqueue 1.29338 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03896 ms - Host latency: 2.10447 ms (enqueue 1.1782 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03352 ms - Host latency: 2.10242 ms (enqueue 1.2033 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03528 ms - Host latency: 2.10095 ms (enqueue 1.19661 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05825 ms - Host latency: 2.12664 ms (enqueue 1.19343 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.04878 ms - Host latency: 2.11426 ms (enqueue 1.19822 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03709 ms - Host latency: 2.10442 ms (enqueue 1.18682 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0377 ms - Host latency: 2.10442 ms (enqueue 1.24814 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03857 ms - Host latency: 2.10442 ms (enqueue 1.17722 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03826 ms - Host latency: 2.10564 ms (enqueue 1.19248 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02815 ms - Host latency: 2.09399 ms (enqueue 1.19275 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01873 ms - Host latency: 2.09075 ms (enqueue 1.29202 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0407 ms - Host latency: 2.12305 ms (enqueue 1.71443 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05701 ms - Host latency: 2.12383 ms (enqueue 1.19116 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05876 ms - Host latency: 2.13337 ms (enqueue 1.20227 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05708 ms - Host latency: 2.12261 ms (enqueue 1.13909 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.04507 ms - Host latency: 2.11077 ms (enqueue 1.17295 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03855 ms - Host latency: 2.1031 ms (enqueue 1.17463 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03833 ms - Host latency: 2.10601 ms (enqueue 1.19629 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03906 ms - Host latency: 2.10483 ms (enqueue 1.19631 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.03767 ms - Host latency: 2.10439 ms (enqueue 1.19121 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.02522 ms - Host latency: 2.09211 ms (enqueue 1.20623 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01921 ms - Host latency: 2.09001 ms (enqueue 1.16895 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.01848 ms - Host latency: 2.08516 ms (enqueue 1.18008 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.04744 ms - Host latency: 2.1135 ms (enqueue 1.18198 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05676 ms - Host latency: 2.12478 ms (enqueue 1.18247 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05854 ms - Host latency: 2.12612 ms (enqueue 1.18782 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05662 ms - Host latency: 2.12214 ms (enqueue 1.13367 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05872 ms - Host latency: 2.12463 ms (enqueue 1.2145 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.04058 ms - Host latency: 2.10535 ms (enqueue 1.1407 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07239 ms - Host latency: 2.13701 ms (enqueue 1.13743 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07749 ms - Host latency: 2.14224 ms (enqueue 1.13652 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07651 ms - Host latency: 2.14148 ms (enqueue 1.13003 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07644 ms - Host latency: 2.14099 ms (enqueue 1.15591 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.0782 ms - Host latency: 2.14307 ms (enqueue 1.15247 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.06016 ms - Host latency: 2.12661 ms (enqueue 1.16174 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.10146 ms - Host latency: 2.17378 ms (enqueue 1.19778 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.1019 ms - Host latency: 2.16846 ms (enqueue 1.20339 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.1012 ms - Host latency: 2.16714 ms (enqueue 1.15212 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.09602 ms - Host latency: 2.16113 ms (enqueue 1.15796 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07715 ms - Host latency: 2.14209 ms (enqueue 1.14397 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.07749 ms - Host latency: 2.14141 ms (enqueue 1.15261 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.06836 ms - Host latency: 2.13342 ms (enqueue 1.19297 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05654 ms - Host latency: 2.1228 ms (enqueue 1.15247 ms)\n",
            "[11/25/2024-09:06:52] [I] Average on 10 runs - GPU latency: 2.05808 ms - Host latency: 2.12273 ms (enqueue 1.16155 ms)\n",
            "[11/25/2024-09:06:52] [I] \n",
            "[11/25/2024-09:06:52] [I] === Performance summary ===\n",
            "[11/25/2024-09:06:52] [I] Throughput: 486.979 qps\n",
            "[11/25/2024-09:06:52] [I] Latency: min = 2.05969 ms, max = 2.3689 ms, mean = 2.11697 ms, median = 2.10791 ms, percentile(90%) = 2.16479 ms, percentile(95%) = 2.17017 ms, percentile(99%) = 2.20569 ms\n",
            "[11/25/2024-09:06:52] [I] Enqueue Time: min = 1.10571 ms, max = 2.1037 ms, mean = 1.20058 ms, median = 1.17572 ms, percentile(90%) = 1.24731 ms, percentile(95%) = 1.34521 ms, percentile(99%) = 1.69806 ms\n",
            "[11/25/2024-09:06:52] [I] H2D Latency: min = 0.0568848 ms, max = 0.262268 ms, mean = 0.0622318 ms, median = 0.0600586 ms, percentile(90%) = 0.0649414 ms, percentile(95%) = 0.0668335 ms, percentile(99%) = 0.115906 ms\n",
            "[11/25/2024-09:06:52] [I] GPU Compute Time: min = 1.9967 ms, max = 2.14099 ms, mean = 2.04922 ms, median = 2.03979 ms, percentile(90%) = 2.09888 ms, percentile(95%) = 2.10278 ms, percentile(99%) = 2.13745 ms\n",
            "[11/25/2024-09:06:52] [I] D2H Latency: min = 0.00390625 ms, max = 0.0126953 ms, mean = 0.00552297 ms, median = 0.00524902 ms, percentile(90%) = 0.00698853 ms, percentile(95%) = 0.00738525 ms, percentile(99%) = 0.00817871 ms\n",
            "[11/25/2024-09:06:52] [I] Total Host Walltime: 3.00629 s\n",
            "[11/25/2024-09:06:52] [I] Total GPU Compute Time: 3.00005 s\n",
            "[11/25/2024-09:06:52] [W] * GPU compute time is unstable, with coefficient of variance = 1.37946%.\n",
            "[11/25/2024-09:06:52] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
            "[11/25/2024-09:06:52] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
            "[11/25/2024-09:06:52] [I] \n",
            "&&&& PASSED TensorRT.trtexec [TensorRT v100200] # /usr/src/tensorrt/bin/trtexec --int8 --onnx=./models/disastereye.onnx --saveEngine=./models/disastereye.trt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# TensorRT\n",
        "import tensorrt as trt\n",
        "print(f\"TensorRT version: {trt.__version__}\")\n",
        "\n",
        "# PyTorch and Torchvision\n",
        "import torch, torchvision\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "\n",
        "# NumPy\n",
        "import numpy as np\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "# pycuda\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "print(f\"PyCUDA version: {cuda.get_version()}\")\n",
        "\n",
        "# PIL (Pillow)\n",
        "from PIL import Image\n",
        "print(f\"Pillow version: {Image.__version__}\")\n",
        "\n",
        "# Additional information\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "from torchvision import transforms\n",
        "\n",
        "print(\"Additional libraries imported successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3IiEpqlMSz",
        "outputId": "b719f8c7-e5c4-4c44-b86b-da1c766617ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "TensorRT version: 10.2.0\n",
            "PyTorch version: 2.5.1+cu121\n",
            "Torchvision version: 0.20.1+cu121\n",
            "NumPy version: 1.26.4\n",
            "PyCUDA version: (12, 2, 0)\n",
            "Pillow version: 11.0.0\n",
            "Additional libraries imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNwF6QR7xC_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a10181-aeb2-426a-b076-8610d7a19bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: disastereye\n",
            "Prediction: Flood, Time: 4.11ms, FPS: 243.22\n",
            "Model size: 33.35MB\n",
            "\n",
            "Dataset: dfan\n",
            "Prediction: Forest Fire, Time: 4.18ms, FPS: 239.06\n",
            "Model size: 33.28MB\n",
            "\n",
            "Dataset: aider\n",
            "Prediction: Traffic Accident, Time: 4.15ms, FPS: 240.78\n",
            "Model size: 33.21MB\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorrt as trt\n",
        "# print(trt.__version__)\n",
        "import torch, torchvision\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from torchvision import transforms\n",
        "import math\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def build_transform(input_size=224,\n",
        "                    interpolation='bicubic',\n",
        "                    mean=(0.485, 0.456, 0.406),\n",
        "                    std=(0.229, 0.224, 0.225),\n",
        "                    crop_pct=0.875):\n",
        "\n",
        "    def _pil_interp(method):\n",
        "        if method == 'bicubic':\n",
        "            return Image.BICUBIC\n",
        "        elif method == 'lanczos':\n",
        "            return Image.LANCZOS\n",
        "        elif method == 'hamming':\n",
        "            return Image.HAMMING\n",
        "        else:\n",
        "            return Image.BILINEAR\n",
        "\n",
        "    resize_im = input_size > 32\n",
        "    t = []\n",
        "    if resize_im:\n",
        "        size = int(math.floor(input_size / crop_pct))\n",
        "        ip = _pil_interp(interpolation)\n",
        "        t.append(\n",
        "            transforms.Resize(\n",
        "                size,\n",
        "                interpolation=ip),\n",
        "        )\n",
        "        t.append(transforms.CenterCrop(input_size))\n",
        "\n",
        "    t.append(transforms.ToTensor())\n",
        "    t.append(transforms.Normalize(mean, std))\n",
        "    return transforms.Compose(t)\n",
        "\n",
        "class TensorRTInference:\n",
        "    def __init__(self, engine_path):\n",
        "        self.logger = trt.Logger(trt.Logger.WARNING)\n",
        "        self.runtime = trt.Runtime(self.logger)\n",
        "        self.engine = self.load_engine(engine_path)\n",
        "        self.context = self.engine.create_execution_context()\n",
        "\n",
        "        # Allocate buffers\n",
        "        self.inputs, self.outputs, self.bindings, self.stream = self.allocate_buffers(self.engine)\n",
        "\n",
        "    def load_engine(self, engine_path):\n",
        "        with open(engine_path, \"rb\") as f:\n",
        "            engine = self.runtime.deserialize_cuda_engine(f.read())\n",
        "        return engine\n",
        "\n",
        "    class HostDeviceMem:\n",
        "        def __init__(self, host_mem, device_mem):\n",
        "            self.host = host_mem\n",
        "            self.device = device_mem\n",
        "\n",
        "    def allocate_buffers(self, engine):\n",
        "        inputs, outputs, bindings = [], [], []\n",
        "        stream = cuda.Stream()\n",
        "\n",
        "        for i in range(engine.num_io_tensors):\n",
        "            tensor_name = engine.get_tensor_name(i)\n",
        "            size = trt.volume(engine.get_tensor_shape(tensor_name))\n",
        "            dtype = trt.nptype(engine.get_tensor_dtype(tensor_name))\n",
        "\n",
        "            # Allocate host and device buffers\n",
        "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
        "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
        "\n",
        "            # Append the device buffer address to device bindings\n",
        "            bindings.append(int(device_mem))\n",
        "\n",
        "            # Append to the appropriate input/output list\n",
        "            if engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:\n",
        "                inputs.append(self.HostDeviceMem(host_mem, device_mem))\n",
        "            else:\n",
        "                outputs.append(self.HostDeviceMem(host_mem, device_mem))\n",
        "        return inputs, outputs, bindings, stream\n",
        "\n",
        "    def infer(self, input_data):\n",
        "        # Transfer input data to device\n",
        "        np.copyto(self.inputs[0].host, input_data.ravel())\n",
        "        cuda.memcpy_htod_async(self.inputs[0].device, self.inputs[0].host, self.stream)\n",
        "\n",
        "        # Set tensor address\n",
        "        for i in range(self.engine.num_io_tensors):\n",
        "            self.context.set_tensor_address(self.engine.get_tensor_name(i), self.bindings[i])\n",
        "\n",
        "        # Run inference\n",
        "        self.context.execute_async_v3(stream_handle=self.stream.handle)\n",
        "\n",
        "        # Transfer predictions back\n",
        "        cuda.memcpy_dtoh_async(self.outputs[0].host, self.outputs[0].device, self.stream)\n",
        "\n",
        "        # Synchronize the stream\n",
        "        self.stream.synchronize()\n",
        "\n",
        "        return self.outputs[0].host\n",
        "\n",
        "def evaluate_trt(engine_path, image, dataset):\n",
        "    trt_inference = TensorRTInference(engine_path)\n",
        "\n",
        "    if dataset == \"disastereye\":\n",
        "      labels = ['Conflict', 'Fire', 'Flood', 'Landslide', 'Mudslide', 'Normal', 'Post Earthquake', 'Traffic Accident']\n",
        "    elif dataset == \"dfan\":\n",
        "      labels = ['Boad Fire', 'Building Fire', 'Bus Fire', 'Car Fire', 'Cargo Fire', 'Electric Fire', 'Forest Fire', 'Non Fire', 'PickUp Fire', 'SUV Fire', 'Train Fire', 'Van Fire']\n",
        "    else:\n",
        "      labels = ['Collapsed Building', 'Fire', 'Flood', 'Normal', 'Traffic Accident']\n",
        "    labels = labels\n",
        "\n",
        "    start_time = time.time()\n",
        "    image = image.numpy()\n",
        "\n",
        "    # Run inference\n",
        "    output = trt_inference.infer(image)\n",
        "    predicted = np.argmax(output)\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    print(\"Prediction: {}, Time: {:.2f}ms, FPS: {:.2f}\".format(labels[predicted], (duration * 1000), (1 / duration)))\n",
        "\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "crop_pct = 0.9\n",
        "transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
        "\n",
        "image_paths = ['./images/DisasterEye_flood.png', './images/DFAN_forest_fire.jpg', './images/AIDER_traffic_accident.jpg']\n",
        "engine_paths = [\"./models/disastereye.trt\", \"./models/dfan.trt\", \"./models/aider.trt\"]\n",
        "dataset = [\"disastereye\", \"dfan\", \"aider\"]\n",
        "\n",
        "for i in range(3):\n",
        "  print(\"Dataset:\", dataset[i])\n",
        "  img = Image.open(image_paths[i]).convert('RGB')\n",
        "  img_transformed = transform(img)\n",
        "  img_transformed = img_transformed.unsqueeze(0)\n",
        "\n",
        "  evaluate_trt(engine_paths[i], img_transformed, dataset[i])\n",
        "  model_size = os.path.getsize(engine_paths[i])\n",
        "  print(\"Model size: {:.2f}MB\".format(model_size / 1e6))\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "240.78: 499.307 = x : 93.78"
      ],
      "metadata": {
        "id": "CFkz0WVkcy66"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}